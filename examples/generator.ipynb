{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Hydra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: hydra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hydra` is a Python library we use to load and manage configuration files. It is a powerful tool that allows us to define configuration files in a structured way and load them into our Python code.\n",
    "\n",
    "To use `hydra`, we need to define a relative path to a configuration file (folder with configuration files) and then load it into our code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"./../configs\" # Path to the config files. Should be relative to the script location!\n",
    "cfg_name = \"test\" # Name of the config file to load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of loading configuration files using `hydra`:\n",
    "\n",
    "1. **Imperative API**: This is the most common way of loading configuration files. We use the `OmegaConf` object to load the configuration files and access the configuration parameters.\n",
    "\n",
    "Use the following code to load a configuration file using the imperative API:\n",
    "\n",
    "```python\n",
    "with hydra.initialize(config_path=cfg_path):\n",
    "    cfg = hydra.compose(config_name=cfg_name)\n",
    "```\n",
    "\n",
    "Inside the context manager (`with` block), we can access the configuration parameters using the `cfg` object directly.\n",
    "\n",
    "2. **Declarative API**: This is a new way of loading configuration files. We use the `@hydra.main()` decorator to load the configuration files and access the configuration parameters.\n",
    "\n",
    "```python\n",
    "@hydra.main(config_path=cfg_path, config_name=cfg_name)\n",
    "def my_app(cfg: DictConfig) -> None:\n",
    "    pass\n",
    "```\n",
    "The `cfg` object is passed as an argument to the function decorated with `@hydra.main()`.\n",
    "\n",
    "In this notebook, we will be using Imperative API since the Declarative API is not supported in Jupyter notebooks. In scripts, however, you can use the Declarative API to load configuration files.\n",
    "\n",
    "`hydra.compose()` takes care of loading all the configuration files mentioned in the passed file, and merges them into a single configuration object. It also resolves the configuration parameters and provides a clean interface to access the configuration parameters.\n",
    "\n",
    "It is called automatically when we use the `@hydra.main()` decorator, but we need to call it explicitly when using the imperative API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imgs(data, slice=128):\n",
    "    print(\"Data keys:\", data.keys())\n",
    "    if 'name' in data:\n",
    "        print(\"Name:\", data['name'])\n",
    "    \n",
    "    # print shape, type, range, device\n",
    "    print(f\"Image shape: {data['image'].shape}, type: {data['image'].dtype}, range: [{data['image'].min()}, {data['image'].max()}], device: {data['image'].device}\")\n",
    "    print(f\"Label shape: {data['label'].shape}, type: {data['label'].dtype}, range: [{data['label'].min()}, {data['label'].max()}], device: {data['label'].device}\")\n",
    "\n",
    "\n",
    "    # if cuda tensor, move to cpu\n",
    "    if data[\"image\"].is_cuda:\n",
    "        data[\"image\"] = data[\"image\"].cpu()\n",
    "    if data[\"label\"].is_cuda:\n",
    "        data[\"label\"] = data[\"label\"].cpu()\n",
    "    \n",
    "    # remove channel dimension\n",
    "    data[\"image\"] = data[\"image\"].squeeze()\n",
    "    data[\"label\"] = data[\"label\"].squeeze()\n",
    "    \n",
    "    # plot image label\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(data[\"image\"][:, slice, :], cmap=\"gray\")\n",
    "    axes[0].set_title(\"Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(data[\"label\"][:, slice, :], cmap='jet')\n",
    "    axes[1].set_title(\"Label\")\n",
    "    axes[1].axis(\"off\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths to the corresponding config files\n",
    "\n",
    "cfg_path = \"./../configs/dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = 'testing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`configs/dataset/testing.yaml` contains following configuration for real images dataset:\n",
    "\n",
    "```\n",
    "defaults:\n",
    "  - transforms/inference\n",
    "\n",
    "_target_: fetalsyngen.data.datasets.FetalTestDataset\n",
    "bids_path: ./data\n",
    "sub_list: null\n",
    "```\n",
    "\n",
    "See how in the code below we load the configuration file and hydra takes care of loading the `configs/dataset/transforms/inference.yaml` file as well and sets the `transforms` parameter in the configuration object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=cfg_path, version_base='1.2'):\n",
    "    cfg = hydra.compose(config_name=cfg_name)\n",
    "    print(f'Composed config: {cfg}')\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "    cfg.bids_path = './../data' # update the BIDS path to the relative path from current script location\n",
    "    dataset = hydra.utils.instantiate(cfg)\n",
    "    sample = dataset[0]\n",
    "    plot_imgs(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real training images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"real_train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`configs/dataset/real_train.yaml` contains following configuration for real images dataset:\n",
    "\n",
    "```\n",
    "defaults:\n",
    "  - generator/default\n",
    "\n",
    "_target_: fetalsyngen.data.datasets.FetalSynthDataset\n",
    "bids_path: ./data\n",
    "seed_path: null\n",
    "sub_list: null\n",
    "load_image: True\n",
    "image_as_intensity: True\n",
    "```\n",
    "\n",
    "See how in the code below we load the configuration file and hydra takes care of loading the `configs/dataset/generator/default.yaml` file as well and sets the `generator` parameter in the configuration object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=cfg_path, version_base=\"1.2\"):\n",
    "    cfg = hydra.compose(config_name=cfg_name)\n",
    "    print(f\"Composed config: {cfg}\")\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "    cfg.bids_path = \"./../data\"  # update the BIDS path to the relative path from current script location\n",
    "    dataset = hydra.utils.instantiate(cfg)\n",
    "    sample = dataset[0]\n",
    "    plot_imgs(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic images dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_name = \"synth_train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`configs/dataset/synth_train.yaml` contains following configuration for real images dataset:\n",
    "\n",
    "```\n",
    "defaults:\n",
    "  - generator/default\n",
    "\n",
    "_target_: fetalsyngen.data.datasets.FetalSynthDataset\n",
    "bids_path: ./data\n",
    "seed_path: ./data/derivatives/seeds\n",
    "sub_list: null\n",
    "load_image: False\n",
    "image_as_intensity: False\n",
    "```\n",
    "\n",
    "See how in the code below we load the configuration file and hydra takes care of loading the `configs/dataset/generator/default.yaml` file as well and sets the `generator` parameter in the configuration object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path=cfg_path, version_base=\"1.2\"):\n",
    "    cfg = hydra.compose(config_name=cfg_name)\n",
    "    cfg.bids_path = \"./../data\"  # update the BIDS path to the relative path from current script location\n",
    "    cfg.seed_path = \"./../data/derivatives/seeds\"\n",
    "    print(f\"Composed config: {cfg}\")\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "    cfg.bids_path = \"./../data\"  # update the BIDS path to the relative path from current script location\n",
    "    dataset = hydra.utils.instantiate(cfg)\n",
    "    sample = dataset[0]\n",
    "    plot_imgs(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetalsyngen.data.datasets import FetalSynthDataset\n",
    "\n",
    "from fetalsyngen.generator.model import FetalSynthGen\n",
    "from fetalsyngen.generator.augmentation.synthseg import RandBiasField, RandGamma, RandNoise, RandResample\n",
    "from fetalsyngen.generator.deformation.affine_nonrigid import  SpatialDeformation\n",
    "from fetalsyngen.generator.intensity.rand_gmm import  ImageFromSeeds\n",
    "\n",
    "\n",
    "intensity_generator = ImageFromSeeds(\n",
    "    min_subclusters=1,\n",
    "    max_subclusters=3,\n",
    "    seed_labels=[ 0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
    "    ],\n",
    "    generation_classes=[\n",
    "        0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49,\n",
    "    ],\n",
    "    meta_labels=4,\n",
    ")\n",
    "spatial_deform = SpatialDeformation(max_rotation=20, max_shear=0.02,max_scaling=0.11,\n",
    "                                    size=(256, 256, 256), prob=1, nonlinear_transform=True,\n",
    "                                    nonlin_scale_min=0.03, nonlin_scale_max=0.06,\n",
    "                                    nonlin_std_max=4, flip_prb=0.5, device='cuda:0')\n",
    "resampler = RandResample(prob=0.5, max_resolution=1.5, min_resolution=0.5)\n",
    "bias_field = RandBiasField(prob=0.5, scale_min=0.004, scale_max=0.02, std_min=0.01, std_max=0.3)\n",
    "noise = RandNoise(prob=0.5, std_min=5, std_max=15)\n",
    "gamma = RandGamma(prob=0.5, gamma_std=0.1)\n",
    "\n",
    "generator = FetalSynthGen(shape=(256, 256, 256),\n",
    "                          resolution=(0.5, 0.5, 0.5),\n",
    "                          device='cuda:0',\n",
    "                          intensity_generator=intensity_generator,\n",
    "                          spatial_deform=spatial_deform,\n",
    "                          resampler=resampler,\n",
    "                          bias_field=bias_field,\n",
    "                          noise=noise,\n",
    "                          gamma=gamma,\n",
    "                          )\n",
    "\n",
    "dataset = FetalSynthDataset(bids_path='./../data', generator=generator,\n",
    "                            seed_path='./../data/derivatives/seeds', \n",
    "                            sub_list=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the generated configuration object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different images will be generated for the same dataset index due to the randomized generator. See example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imgs(dataset[0])\n",
    "plot_imgs(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you want to generate similar images for the same dataset index, you can use  pass to the generator the genparams dictionary with the generation parameters. These generation parameters can be obtained if using the `dataset.sample_with_meta()` rather than `dataset.__getitem__()`.\n",
    "\n",
    "See how in example below we are able to generate the same images for the same dataset index by passing the genparams dictionary to the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset.sample_with_meta(0)\n",
    "sample_copy = dataset.sample_with_meta(0, genparams=sample['generation_params'])\n",
    "plot_imgs(data=sample)\n",
    "plot_imgs(data=sample_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note!\n",
    "If a generation parameter is set to None, it will be randomly selected by the generator. If you want to generate the same images for the same dataset index, you need to pass the genparams dictionary with the generation parameters.\n",
    "\n",
    "A Small script below prints the generation parameters that are  different between to sampled images with the same generation parameters.\n",
    "If they are not printed they are the same.\n",
    "\n",
    "Note that the generation parameters define **'strength'** of the augmentation. Not necessarily the augmentation itself voxel-wise.\n",
    "\n",
    "\n",
    "If the generation parameter is None, it still might be randomly selected by the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sample[\"generation_params\"]\n",
    "b = sample_copy[\"generation_params\"]\n",
    "\n",
    "# compare all the values (including nested dictionaries) to be the same and print the differences\n",
    "def compare_dicts(a, b, path=\"\"):\n",
    "    def robust_compare(a, b):\n",
    "        # print(f\"Comparing {a} and {b}\")\n",
    "        if isinstance(a, np.ndarray) and isinstance(b, np.ndarray):\n",
    "            return not np.all(a == b)\n",
    "        elif isinstance(a, torch.Tensor) and isinstance(b, torch.Tensor):\n",
    "            return not torch.all(a == b)\n",
    "        elif type(a) != type(b):\n",
    "            return True\n",
    "        \n",
    "        return a != b\n",
    "\n",
    "        # return a!=b\n",
    "\n",
    "    for key in a.keys():\n",
    "        if key not in b:\n",
    "            print(f\"Key {path}.{key} not found in b\")\n",
    "        elif isinstance(a[key], dict):\n",
    "            compare_dicts(a[key], b[key], path=f\"{path}.{key}\")\n",
    "        elif robust_compare(a[key], b[key]):\n",
    "            print(f\"Key {path}.{key} has different values: {a[key]} != {b[key]}\")\n",
    "\n",
    "compare_dicts(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FetalSynthGen","text":""},{"location":"#introduction","title":"Introduction","text":"<p>FetalSynthGen is a synthetic data generator created to address the challenges of limited data and domain shifts in fetal brain MRI analysis. It is based on the domain randomization approach of SynthSeg [1], which uses anatomical segmentations to create diverse synthetic images.</p> <p>It's application for fetal brain tissue segmentation is described in [2, 3].</p> <p>Below is a brief overview of the key components of the FetalSynthGen pipeline: </p> <ul> <li> <p>Input: The generator begins with a dataset of segmentation maps, which serve as anatomical priors of the simulated fetal brain.</p> </li> <li> <p>Meta-Labels: Instead of directly using the original segmentation labels, the method first merges these labels into four meta-classes: white matter (WM), gray matter (GM), cerebrospinal fluid (CSF), and non-brain tissue (including skull and surrounding maternal tissue).</p> </li> <li> <p>Intensity Clustering: Within each meta-class, the generator uses the Expectation-Maximization (EM) algorithm for intensity clustering, which divides each meta-class into subclasses, capturing the heterogeneity of the simulated brain tissues. The number of subclasses is sampled from a random uniform distribution.</p> </li> <li>Intensity Generation: For each subclass, the generator then samples intensities from a Gaussian Mixture Model (GMM) with randomized parameters. This method creates images with varied contrasts that although often exceed what is realistic, ensure that the model learns features robust to  domain shifts related to intensity or contrast.</li> <li>Spatial Transformations: After generating intensities, the synthetic images undergo spatial transformations, including affine and non-rigid diffeomorphic deformations. These simulate variations in image resolution and partial volume effects.</li> <li>Artifact Simulation: The generator corrupts the images by adding a bias field, performing intensity transformations, and simulating various image resolutions.</li> </ul> <p>The output of the generator is a paired set of synthetic images and corresponding synthetic segmentations that can be used to train a segmentation model, super-resolution or brain-embedding model.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-source","title":"From Source","text":"<pre><code>git clone https://github.com/Medical-Image-Analysis-Laboratory/fetalsyngen\ncd fetalsyngen\n# create a conda environment from environment.yml\nconda env create -f environment.yml\n# activate the environment\nconda activate fetalsyngen\n# install the package\npip install -e .\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This research was funded by the Swiss National Science Foundation (182602 and 215641), ERA-NET Neuron MULTI-FACT project (SNSF 31NE30 203977). We acknowledge the Leenaards and Jeantet Foundations as well as CIBM Center for Biomedical Imaging, a Swiss research center of excellence founded and supported by CHUV, UNIL, EPFL, UNIGE and HUG.</p>"},{"location":"#references","title":"References","text":"<ol> <li>Billot, Benjamin, et al. \u201cSynthSeg: Segmentation of Brain MRI Scans of Any Contrast and Resolution without Retraining.\u201d Medical Image Analysis, vol. 86, 25 Feb. 2023, pp. 102789\u2013102789, www.sciencedirect.com/science/article/pii/S1361841523000506, https://doi.org/10.1016/j.media.2023.102789.</li> <li>Vladyslav Zalevskyi, et al. \u201cImproving Cross-Domain Brain Tissue Segmentation in Fetal MRI with Synthetic Data.\u201d Lecture Notes in Computer Science, 1 Jan. 2024, pp. 437\u2013447, link.springer.com/chapter/10.1007/978-3-031-72378-0_41, https://doi.org/10.1007/978-3-031-72378-0_41. </li> <li>Vladyslav Zalevskyi, et al. \u201cMaximizing Domain Generalization in Fetal Brain Tissue Segmentation: The Role of Synthetic Data Generation, Intensity Clustering and Real Image Fine-Tuning.\u201d ArXiv.org, 2024, arxiv.org/abs/2411.06842.</li> </ol> <p>\u200c \u200c</p> <p>\u200c</p>"},{"location":"configs/","title":"Configs","text":"<p>We use Hydra to manage configurations and instantiate classes in the <code>FetalSynthGen</code> pipeline. It allows us to define configurations in YAML files and instantiate classes with these configurations. This makes it easy to modify parameters and experiment with different settings.</p> <p>See the Hydra documentation for more information.</p>"},{"location":"configs/#quick-hydra-overview","title":"Quick hydra overview","text":"<p>Configuration files are stored in the <code>configs</code> directory.</p> <p>Each file is a <code>.yaml</code> file that contains the parameters for the generation pipeline and defines an instantiation of a class.</p> <p>Fields in the configuration files can be overridden from the command line or from other configuration files. Some special fields are:</p> <ul> <li><code>_target_</code> field in the configuration file specifies the class to be instantiated. All other fields are passed as arguments to the class constructor. It can be any callable object, including classes, functions, and lambdas, from any module in the Python path (local or external).</li> <li><code>defaults</code> field in the configuration file specifies the default configuration file to be used, that is merged with the current configuration file. If a field is present in both files, the one in the current file takes precedence.</li> </ul>  For example  <pre><code>defaults:\n    - generator/default\n</code></pre> <p>will load the <code>generator/default.yaml</code> file and will make all fields from the <code>generator/default.yaml</code> file available in the current configuration file from the <code>generator.*</code> namespace.</p> <ul> <li><code>null</code> is used in the configuration files to specify a <code>None</code> value in Python.</li> <li>expressions like <code>\"${var}\"</code> can be used to access variable value in the same level of a given config while <code>\"${..var}\"</code> can be used to access variable value from the parent config.</li> </ul>"},{"location":"configs/#configuration-files","title":"Configuration Files","text":"<p>We provide a variety of ready-to-use configurations for different tasks. These configuration files are stored in the <code>fetalsyngen/configs/dataset</code> directory.</p> <p>To use them, copy the configuration files to your project root directory into <code>configs/dataset</code>. Feel free to modify these configurations to suit the specific requirements of your project.</p>"},{"location":"configs/#validationtesting-dataset","title":"Validation/Testing Dataset","text":"<p>Dataset configuration for loading real images and segmentations. Used for testing and validation on real data. See <code>/datasets/#fetalsyngen.data.datasets.FetalTestDataset</code> for more details. <pre><code>defaults:\n  - transforms/inference\n\n_target_: fetalsyngen.data.datasets.FetalTestDataset\nbids_path: ./data\nsub_list: null\n</code></pre></p>"},{"location":"configs/#real-images-with-synthetic-transformations","title":"Real images with synthetic transformations","text":"<p>Dataset configuration for applying the same transformations used in the generation of synthetic data to real images and segmentations. See <code>/datasets/#fetalsyngen.data.datasets.FetalSynthDataset</code> for more details.</p> <p><code>configs/dataset/real_train.yaml</code> &gt; <pre><code>defaults:\n  - generator/default\n\n_target_: fetalsyngen.data.datasets.FetalSynthDataset\nbids_path: ./data\nseed_path: null\nsub_list: null\nload_image: True\nimage_as_intensity: True\n</code></pre></p>"},{"location":"configs/#synthetic-images-and-segmentations","title":"Synthetic images and segmentations","text":"<p>Dataset configuration for creating synthetic images and segmentations on the fly. See <code>/datasets/#fetalsyngen.data.datasets.FetalSynthDataset</code> for more details.</p> <p><code>configs/dataset/synth_train.yaml</code> &gt; <pre><code>defaults:\n  - generator/default\n\n_target_: fetalsyngen.data.datasets.FetalSynthDataset\nbids_path: ./data\nseed_path: ./data/derivatives/seeds\nsub_list: null\nload_image: False\nimage_as_intensity: False\n</code></pre></p>"},{"location":"configs/#default-generator-configuration","title":"Default Generator Configuration","text":"<p><code>configs/dataset/generator/default.yaml</code> &gt; <pre><code>_target_: fetalsyngen.generator.model.FetalSynthGen\n\nshape: [256, 256, 256]\nresolution: [0.5, 0.5, 0.5]\ndevice: cuda # cuda ~6x faster than cpu\n\nintensity_generator:\n  _target_: fetalsyngen.generator.intensity.rand_gmm.ImageFromSeeds\n  min_subclusters: 1\n  max_subclusters: 3\n  seed_labels: [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n  generation_classes: [0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n\nspatial_deform:\n  _target_: fetalsyngen.generator.deformation.affine_nonrigid.SpatialDeformation\n  device: \"${..device}\" # uses the device from the generator\n  size: ${..shape} # uses the shape from the generator\n  flip_prb: 0.5\n\n  max_rotation: 20\n  max_shear: 0.02\n  max_scaling: 0.1\n\n  nonlinear_transform: True\n  nonlin_scale_min: 0.03\n  nonlin_scale_max: 0.06\n  nonlin_std_max: 4\n\nresampler:\n  _target_: fetalsyngen.generator.augmentation.synthseg.RandResample\n  min_resolution: 1.9\n  max_resolution: 2\n  prob: 1\n\nbias_field:\n  _target_: fetalsyngen.generator.augmentation.synthseg.RandBiasField\n  prob: 1\n  scale_min: 0.004 \n  scale_max: 0.02\n  std_min:  0.01\n  std_max: 0.3\n\ngamma:\n  _target_: fetalsyngen.generator.augmentation.synthseg.RandGamma\n  prob: 1\n  gamma_std: 0.1\n\nnoise:\n  _target_: fetalsyngen.generator.augmentation.synthseg.RandNoise\n  prob: 1\n  std_min: 5\n  std_max: 15\n</code></pre></p>"},{"location":"datasets/","title":"Datasets","text":"<p>Classes for loading and processing datasets.</p> <p>Note</p> <p>\ud83d\udcdd Device: All datasets return samples with tensors on the CPU (even when the synthetic data generation is done on the GPU). This is due to restriction on the GPU usage in the multiprocessing settings, where GPU memory cannot be easily shared between processes.</p> <p>\ud83d\udcdd Dataloader: When using <code>torch.utils.data.DataLoader</code> ensure that you pass <code>multiprocessing_context=\"spawn\"</code> argument to the dataloader object when using <code>FetalSynthDataset</code> to ensure that the spawned processes have access to the GPU.</p>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalDataset","title":"<code>FetalDataset</code>","text":"<p>Abstract class defining a dataset for loading fetal data.</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>class FetalDataset:\n    \"\"\"Abstract class defining a dataset for loading fetal data.\"\"\"\n\n    def __init__(\n        self,\n        bids_path: str,\n        sub_list: list[str] | None,\n    ) -&gt; dict:\n        \"\"\"\n        Args:\n            bids_path: Path to the bids folder with the data.\n            sub_list: List of the subjects to use. If None, all subjects are used.\n\n\n        \"\"\"\n        super().__init__()\n\n        self.bids_path = Path(bids_path)\n        self.subjects = self.find_subjects(sub_list)\n        if self.subjects is None:\n            self.subjects = [x.name for x in self.bids_path.glob(\"sub-*\")]\n        self.sub_ses = [\n            (x, y) for x in self.subjects for y in self._get_ses(self.bids_path, x)\n        ]\n        self.loader = SimpleITKReader()\n        self.scaler = ScaleIntensity(minv=0, maxv=1)\n\n        self.img_paths = self._load_bids_path(self.bids_path, \"T2w\")\n        self.segm_paths = self._load_bids_path(self.bids_path, \"dseg\")\n\n    def find_subjects(self, sub_list):\n        subj_found = [x.name for x in Path(self.bids_path).glob(\"sub-*\")]\n        return list(set(subj_found) &amp; set(sub_list)) if sub_list is not None else None\n\n    def _sub_ses_string(self, sub, ses):\n        return f\"{sub}_{ses}\" if ses is not None else sub\n\n    def _sub_ses_idx(self, idx):\n        sub, ses = self.sub_ses[idx]\n        return self._sub_ses_string(sub, ses)\n\n    def _get_ses(self, bids_path, sub):\n        \"\"\"Get the session names for the subject.\"\"\"\n        sub_path = bids_path / sub\n        ses_dir = [x for x in sub_path.iterdir() if x.is_dir()]\n        ses = []\n        for s in ses_dir:\n            if \"anat\" in s.name:\n                ses.append(None)\n            else:\n                ses.append(s.name)\n\n        return sorted(ses, key=lambda x: x or \"\")\n\n    def _get_pattern(self, sub, ses, suffix, extension=\".nii.gz\"):\n        \"\"\"Get the pattern for the file name.\"\"\"\n        if ses is None:\n            return f\"{sub}/anat/{sub}*_{suffix}{extension}\"\n        else:\n            return f\"{sub}/{ses}/anat/{sub}_{ses}*_{suffix}{extension}\"\n\n    def _load_bids_path(self, path, suffix):\n        \"\"\"\n        \"Check that for a given path, all subjects have a file with the provided suffix\n        \"\"\"\n        files_paths = []\n        for sub, ses in self.sub_ses:\n            pattern = self._get_pattern(sub, ses, suffix)\n            files = list(path.glob(pattern))\n            if len(files) == 0:\n                raise FileNotFoundError(\n                    f\"No files found for requested subject {sub} in {path} \"\n                    f\"({pattern} returned nothing)\"\n                )\n            elif len(files) &gt; 1:\n                raise RuntimeError(\n                    f\"Multiple files found for requested subject {sub} in {path} \"\n                    f\"({pattern} returned {files})\"\n                )\n            files_paths.append(files[0])\n\n        return files_paths\n\n    def __len__(self):\n        return len(self.subjects)\n\n    def __getitem__(self, idx):\n        raise NotImplementedError(\n            \"This method should be implemented in the child class.\"\n        )\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalDataset.__init__","title":"<code>__init__(bids_path, sub_list)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>bids_path</code> <code>str</code> <p>Path to the bids folder with the data.</p> required <code>sub_list</code> <code>list[str] | None</code> <p>List of the subjects to use. If None, all subjects are used.</p> required Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>def __init__(\n    self,\n    bids_path: str,\n    sub_list: list[str] | None,\n) -&gt; dict:\n    \"\"\"\n    Args:\n        bids_path: Path to the bids folder with the data.\n        sub_list: List of the subjects to use. If None, all subjects are used.\n\n\n    \"\"\"\n    super().__init__()\n\n    self.bids_path = Path(bids_path)\n    self.subjects = self.find_subjects(sub_list)\n    if self.subjects is None:\n        self.subjects = [x.name for x in self.bids_path.glob(\"sub-*\")]\n    self.sub_ses = [\n        (x, y) for x in self.subjects for y in self._get_ses(self.bids_path, x)\n    ]\n    self.loader = SimpleITKReader()\n    self.scaler = ScaleIntensity(minv=0, maxv=1)\n\n    self.img_paths = self._load_bids_path(self.bids_path, \"T2w\")\n    self.segm_paths = self._load_bids_path(self.bids_path, \"dseg\")\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalTestDataset","title":"<code>FetalTestDataset</code>","text":"<p>               Bases: <code>FetalDataset</code></p> <p>Dataset class for loading fetal images offline. Used to load test/validation data.</p> <p>Use the <code>transforms</code> argument to pass additional processing steps (scaling, resampling, cropping, etc.).</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>class FetalTestDataset(FetalDataset):\n    \"\"\"Dataset class for loading fetal images offline.\n    Used to load test/validation data.\n\n    Use the `transforms` argument to pass additional processing steps\n    (scaling, resampling, cropping, etc.).\n    \"\"\"\n\n    def __init__(\n        self,\n        bids_path: str,\n        sub_list: list[str] | None,\n        transforms: Compose | None = None,\n    ):\n        \"\"\"\n        Args:\n            bids_path: Path to the bids folder with the data.\n            sub_list: List of the subjects to use. If None, all subjects are used.\n            transforms: Compose object with the transformations to apply.\n                Default is None, no transformations are applied.\n\n        !!! Note\n            We highle recommend using the `transforms` arguments with at\n            least the re-oriented transform to RAS and the intensity scaling\n            to `[0, 1]` to ensure the data consistency.\n\n            See [inference.yaml](https://github.com/Medical-Image-Analysis-Laboratory/fetalsyngen/blob/dev/configs/dataset/transforms/inference.yaml) for an example of the transforms configuration.\n        \"\"\"\n        super().__init__(bids_path, sub_list)\n        self.transforms = transforms\n\n    def _load_data(self, idx):\n        # load the image and segmentation\n        image = self.loader(self.img_paths[idx], interp=\"linear\")\n        segm = self.loader(self.segm_paths[idx], interp=\"nearest\")\n\n        if len(image.shape) == 3:\n            # add channel dimension\n            image = image.unsqueeze(0)\n            segm = segm.unsqueeze(0)\n        elif len(image.shape) != 4:\n            raise ValueError(f\"Expected 3D or 4D image, got {len(image.shape)}D image.\")\n\n        # transform name into a single string otherwise collate fails\n        name = self.sub_ses[idx]\n        name = self._sub_ses_string(name[0], ses=name[1])\n\n        return {\"image\": image, \"label\": segm.long(), \"name\": name}\n\n    def __getitem__(self, idx) -&gt; dict:\n        \"\"\"\n        Returns:\n            Dictionary with the `image` , `label` and the `name`\n                keys. `image` and `label` are  `torch.float32`\n                [`monai.data.meta_tensor.MetaTensor`](https://docs.monai.io/en/stable/data.html#metatensor)\n                instances  with dimensions `(1, H, W, D)` and `name` is a string\n                of a format `sub_ses` where `sub` is the subject name\n                and `ses` is the session name.\n\n\n        \"\"\"\n        data = self._load_data(idx)\n\n        if self.transforms:\n            data = self.transforms(data)\n        data[\"label\"] = data[\"label\"].long()\n        return data\n\n    def reverse_transform(self, data: dict) -&gt; dict:\n        \"\"\"Reverse the transformations applied to the data.\n\n        Args:\n            data: Dictionary with the `image` and `label` keys,\n                like the one returned by the `__getitem__` method.\n\n        Returns:\n            Dictionary with the `image` and `label` keys where\n                the transformations are reversed.\n        \"\"\"\n        if self.transforms:\n            data = self.transforms.inverse(data)\n        return data\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalTestDataset.__init__","title":"<code>__init__(bids_path, sub_list, transforms=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>bids_path</code> <code>str</code> <p>Path to the bids folder with the data.</p> required <code>sub_list</code> <code>list[str] | None</code> <p>List of the subjects to use. If None, all subjects are used.</p> required <code>transforms</code> <code>Compose | None</code> <p>Compose object with the transformations to apply. Default is None, no transformations are applied.</p> <code>None</code> <p>Note</p> <p>We highle recommend using the <code>transforms</code> arguments with at least the re-oriented transform to RAS and the intensity scaling to <code>[0, 1]</code> to ensure the data consistency.</p> <p>See inference.yaml for an example of the transforms configuration.</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>def __init__(\n    self,\n    bids_path: str,\n    sub_list: list[str] | None,\n    transforms: Compose | None = None,\n):\n    \"\"\"\n    Args:\n        bids_path: Path to the bids folder with the data.\n        sub_list: List of the subjects to use. If None, all subjects are used.\n        transforms: Compose object with the transformations to apply.\n            Default is None, no transformations are applied.\n\n    !!! Note\n        We highle recommend using the `transforms` arguments with at\n        least the re-oriented transform to RAS and the intensity scaling\n        to `[0, 1]` to ensure the data consistency.\n\n        See [inference.yaml](https://github.com/Medical-Image-Analysis-Laboratory/fetalsyngen/blob/dev/configs/dataset/transforms/inference.yaml) for an example of the transforms configuration.\n    \"\"\"\n    super().__init__(bids_path, sub_list)\n    self.transforms = transforms\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalTestDataset.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with the <code>image</code> , <code>label</code> and the <code>name</code> keys. <code>image</code> and <code>label</code> are  <code>torch.float32</code> <code>monai.data.meta_tensor.MetaTensor</code> instances  with dimensions <code>(1, H, W, D)</code> and <code>name</code> is a string of a format <code>sub_ses</code> where <code>sub</code> is the subject name and <code>ses</code> is the session name.</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>def __getitem__(self, idx) -&gt; dict:\n    \"\"\"\n    Returns:\n        Dictionary with the `image` , `label` and the `name`\n            keys. `image` and `label` are  `torch.float32`\n            [`monai.data.meta_tensor.MetaTensor`](https://docs.monai.io/en/stable/data.html#metatensor)\n            instances  with dimensions `(1, H, W, D)` and `name` is a string\n            of a format `sub_ses` where `sub` is the subject name\n            and `ses` is the session name.\n\n\n    \"\"\"\n    data = self._load_data(idx)\n\n    if self.transforms:\n        data = self.transforms(data)\n    data[\"label\"] = data[\"label\"].long()\n    return data\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalTestDataset.reverse_transform","title":"<code>reverse_transform(data)</code>","text":"<p>Reverse the transformations applied to the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary with the <code>image</code> and <code>label</code> keys, like the one returned by the <code>__getitem__</code> method.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with the <code>image</code> and <code>label</code> keys where the transformations are reversed.</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>def reverse_transform(self, data: dict) -&gt; dict:\n    \"\"\"Reverse the transformations applied to the data.\n\n    Args:\n        data: Dictionary with the `image` and `label` keys,\n            like the one returned by the `__getitem__` method.\n\n    Returns:\n        Dictionary with the `image` and `label` keys where\n            the transformations are reversed.\n    \"\"\"\n    if self.transforms:\n        data = self.transforms.inverse(data)\n    return data\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalSynthDataset","title":"<code>FetalSynthDataset</code>","text":"<p>               Bases: <code>FetalDataset</code></p> <p>Dataset class for generating/augmenting on-the-fly fetal images\"</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>class FetalSynthDataset(FetalDataset):\n    \"\"\"Dataset class for generating/augmenting on-the-fly fetal images\" \"\"\"\n\n    def __init__(\n        self,\n        bids_path: str,\n        generator: FetalSynthGen,\n        seed_path: str | None,\n        sub_list: list[str] | None,\n        load_image: bool = False,\n        image_as_intensity: bool = False,\n        transforms: Compose | None = None,\n    ):\n        \"\"\"\n\n        Args:\n            bids_path: Path to the bids-formatted folder with the data.\n            seed_path: Path to the folder with the seeds to use for\n                intensity sampling. See `scripts/seed_generation.py`\n                for details on the data formatting. If seed_path is None,\n                the intensity  sampling step is skipped and the output image\n                intensities will be based on the input image.\n            generator: a class object defining a generator to use.\n            sub_list: List of the subjects to use. If None, all subjects are used.\n            load_image: If **True**, the image is loaded and passed to the generator,\n                where it can be used as the intensity prior instead of a random\n                intensity sampling or spatially deformed with the same transformation\n                field as segmentation and the syntehtic image. Default is **False**.\n            image_as_intensity: If **True**, the image is used as the intensity prior,\n                instead of sampling the intensities from the seeds. Default is **False**.\n        \"\"\"\n        super().__init__(bids_path, sub_list)\n        self.seed_path = Path(seed_path) if isinstance(seed_path, str) else None\n        self.load_image = load_image\n        self.generator = generator\n        self.image_as_intensity = image_as_intensity\n        self.transforms = transforms\n        # parse seeds paths\n        if not self.image_as_intensity and isinstance(self.seed_path, Path):\n            if not self.seed_path.exists():\n                raise FileNotFoundError(\n                    f\"Provided seed path {self.seed_path} does not exist.\"\n                )\n            else:\n                self._load_seed_path()\n\n    def _load_seed_path(self):\n        \"\"\"Load the seeds for the subjects.\"\"\"\n        self.seed_paths = {\n            self._sub_ses_string(sub, ses): defaultdict(dict)\n            for (sub, ses) in self.sub_ses\n        }\n        avail_seeds = [\n            int(x.name.replace(\"subclasses_\", \"\"))\n            for x in self.seed_path.glob(\"subclasses_*\")\n        ]\n        min_seeds_available = min(avail_seeds)\n        max_seeds_available = max(avail_seeds)\n        for n_sub in range(\n            min_seeds_available,\n            max_seeds_available + 1,\n        ):\n            seed_path = self.seed_path / f\"subclasses_{n_sub}\"\n            if not seed_path.exists():\n                raise FileNotFoundError(\n                    f\"Provided seed path {seed_path} does not exist.\"\n                )\n            # load the seeds for the subjects for each meta label 1-4\n            for i in self.generator.intensity_generator.meta_labels:\n                files = self._load_bids_path(seed_path, f\"mlabel_{i}\")\n                for (sub, ses), file in zip(self.sub_ses, files):\n                    sub_ses_str = self._sub_ses_string(sub, ses)\n                    self.seed_paths[sub_ses_str][n_sub][i] = file\n\n    def sample(self, idx, genparams: dict = {}) -&gt; tuple[dict, dict]:\n        \"\"\"\n        Retrieve a single item from the dataset at the specified index.\n\n        Args:\n            idx (int): The index of the item to retrieve.\n            genparams (dict): Dictionary with generation parameters.\n                Used for fixed generation. Should follow exactly the same structure\n                and be of the same type as the returned generation parameters.\n                Can be used to replicate the augmentations (power)\n                used for the generation of a specific sample.\n        Returns:\n            Dictionaries with the generated data and the generation parameters.\n                First dictionary contains the `image`, `label` and the `name` keys.\n                The second dictionary contains the parameters used for the generation.\n\n        !!! Note\n            The `image` is scaled to `[0, 1]` and oriented with the `label` to **RAS**\n            and returned on the device  specified in the `generator` initialization.\n        \"\"\"\n        # use generation_params to track the parameters used for the generation\n        generation_params = {}\n\n        image = (\n            self.loader(\n                self.img_paths[idx], interp=\"linear\", spatial_size=192, resolution=1.0\n            )\n            if self.load_image\n            else None\n        )\n        segm = self.loader(\n            self.segm_paths[idx], interp=\"nearest\", spatial_size=192, resolution=1.0\n        )\n\n        # RANDOM re-orient TODO: MAKE SWTICHABLE!\n        # LR = \"L\" if torch.rand(1) &gt; 0.5 else \"R\"\n        # AP = \"A\" if torch.rand(1) &gt; 0.5 else \"P\"\n        # IS = \"I\" if torch.rand(1) &gt; 0.5 else \"S\"\n        # orient = np.array([LR, AP, IS])\n        # rand_orient_oreder = torch.randperm(3)\n        axcodes = \"RAS\"  # = orient[rand_orient_oreder]\n        orientation = Orientation(axcodes=axcodes)\n        image = orientation(image.unsqueeze(0)).squeeze(0) if self.load_image else None\n        segm = orientation(segm.unsqueeze(0)).squeeze(0)\n\n        # transform name into a single string otherwise collate fails\n        name = self.sub_ses[idx]\n        name = self._sub_ses_string(name[0], ses=name[1])\n\n        # initialize seeds as dictionary\n        # with paths to the seeds volumes\n        # or None if image is to be used as intensity prior\n        if self.seed_path is not None:\n            seeds = self.seed_paths[name]\n        if self.image_as_intensity:\n            seeds = None\n\n        # log input data\n        generation_params[\"idx\"] = idx\n        generation_params[\"img_paths\"] = str(self.img_paths[idx])\n        generation_params[\"segm_paths\"] = str(self.img_paths[idx])\n        generation_params[\"seeds\"] = str(self.seed_path)\n        generation_time_start = time.time()\n\n        # generate the synthetic data\n        gen_output, segmentation, image, synth_params = self.generator.sample(\n            image=image,\n            segmentation=segm,\n            seeds=seeds,\n            genparams=genparams,\n            orientation=orientation,\n        )\n\n        # scale the images to [0, 1]\n        gen_output = self.scaler(gen_output)\n        image = self.scaler(image) if image is not None else None\n\n        # ensure image and segmentation are on the cpu\n        gen_output = gen_output.cpu()\n        segmentation = segmentation.cpu()\n        image = image.cpu() if image is not None else None\n\n        generation_params = {**generation_params, **synth_params}\n        generation_params[\"generation_time\"] = time.time() - generation_time_start\n        data_out = {\n            \"image\": gen_output.unsqueeze(0),\n            \"label\": segmentation.unsqueeze(0).long(),\n        }\n\n        if self.transforms:\n            data_out = self.transforms(data_out)\n        data_out[\"name\"] = name\n\n        return data_out, generation_params\n\n    def __getitem__(self, idx) -&gt; dict:\n        \"\"\"\n        Retrieve a single item from the dataset at the specified index.\n\n        Args:\n            idx (int): The index of the item to retrieve.\n\n        Returns:\n            Dictionary with the `image`, `label` and the `name` keys.\n                `image` and `label` are `torch.float32`\n                [`monai.data.meta_tensor.MetaTensor`](https://docs.monai.io/en/stable/data.html#metatensor)\n                and `name` is a string of a format `sub_ses` where `sub` is the subject name\n                and `ses` is the session name.\n\n        !!!Note\n            The `image` is scaled to `[0, 1]` and oriented to **RAS** and returned on the device\n            specified in the `generator` initialization.\n        \"\"\"\n        data_out, generation_params = self.sample(idx)\n        self.generation_params = generation_params\n        return data_out\n\n    def sample_with_meta(self, idx: int, genparams: dict = {}) -&gt; dict:\n        \"\"\"\n        Retrieve a sample along with its generation parameters\n        and store them in the same dictionary.\n\n        Args:\n            idx: The index of the sample to retrieve.\n            genparams: Dictionary with generation parameters.\n                Used for fixed generation. Should follow exactly the same structure\n                and be of the same type as the returned generation parameters from the `sample()` method.\n                Can be used to replicate the augmentations (power)\n                used for the generation of a specific sample.\n\n        Returns:\n            A dictionary with `image`, `label`, `name` and `generation_params` keys.\n        \"\"\"\n\n        data, generation_params = self.sample(idx, genparams=genparams)\n        data[\"generation_params\"] = generation_params\n        return data\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalSynthDataset.__init__","title":"<code>__init__(bids_path, generator, seed_path, sub_list, load_image=False, image_as_intensity=False, transforms=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>bids_path</code> <code>str</code> <p>Path to the bids-formatted folder with the data.</p> required <code>seed_path</code> <code>str | None</code> <p>Path to the folder with the seeds to use for intensity sampling. See <code>scripts/seed_generation.py</code> for details on the data formatting. If seed_path is None, the intensity  sampling step is skipped and the output image intensities will be based on the input image.</p> required <code>generator</code> <code>FetalSynthGen</code> <p>a class object defining a generator to use.</p> required <code>sub_list</code> <code>list[str] | None</code> <p>List of the subjects to use. If None, all subjects are used.</p> required <code>load_image</code> <code>bool</code> <p>If True, the image is loaded and passed to the generator, where it can be used as the intensity prior instead of a random intensity sampling or spatially deformed with the same transformation field as segmentation and the syntehtic image. Default is False.</p> <code>False</code> <code>image_as_intensity</code> <code>bool</code> <p>If True, the image is used as the intensity prior, instead of sampling the intensities from the seeds. Default is False.</p> <code>False</code> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>def __init__(\n    self,\n    bids_path: str,\n    generator: FetalSynthGen,\n    seed_path: str | None,\n    sub_list: list[str] | None,\n    load_image: bool = False,\n    image_as_intensity: bool = False,\n    transforms: Compose | None = None,\n):\n    \"\"\"\n\n    Args:\n        bids_path: Path to the bids-formatted folder with the data.\n        seed_path: Path to the folder with the seeds to use for\n            intensity sampling. See `scripts/seed_generation.py`\n            for details on the data formatting. If seed_path is None,\n            the intensity  sampling step is skipped and the output image\n            intensities will be based on the input image.\n        generator: a class object defining a generator to use.\n        sub_list: List of the subjects to use. If None, all subjects are used.\n        load_image: If **True**, the image is loaded and passed to the generator,\n            where it can be used as the intensity prior instead of a random\n            intensity sampling or spatially deformed with the same transformation\n            field as segmentation and the syntehtic image. Default is **False**.\n        image_as_intensity: If **True**, the image is used as the intensity prior,\n            instead of sampling the intensities from the seeds. Default is **False**.\n    \"\"\"\n    super().__init__(bids_path, sub_list)\n    self.seed_path = Path(seed_path) if isinstance(seed_path, str) else None\n    self.load_image = load_image\n    self.generator = generator\n    self.image_as_intensity = image_as_intensity\n    self.transforms = transforms\n    # parse seeds paths\n    if not self.image_as_intensity and isinstance(self.seed_path, Path):\n        if not self.seed_path.exists():\n            raise FileNotFoundError(\n                f\"Provided seed path {self.seed_path} does not exist.\"\n            )\n        else:\n            self._load_seed_path()\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalSynthDataset.sample","title":"<code>sample(idx, genparams={})</code>","text":"<p>Retrieve a single item from the dataset at the specified index.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the item to retrieve.</p> required <code>genparams</code> <code>dict</code> <p>Dictionary with generation parameters. Used for fixed generation. Should follow exactly the same structure and be of the same type as the returned generation parameters. Can be used to replicate the augmentations (power) used for the generation of a specific sample.</p> <code>{}</code> <p>Returns:     Dictionaries with the generated data and the generation parameters.         First dictionary contains the <code>image</code>, <code>label</code> and the <code>name</code> keys.         The second dictionary contains the parameters used for the generation.</p> <p>Note</p> <p>The <code>image</code> is scaled to <code>[0, 1]</code> and oriented with the <code>label</code> to RAS and returned on the device  specified in the <code>generator</code> initialization.</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>def sample(self, idx, genparams: dict = {}) -&gt; tuple[dict, dict]:\n    \"\"\"\n    Retrieve a single item from the dataset at the specified index.\n\n    Args:\n        idx (int): The index of the item to retrieve.\n        genparams (dict): Dictionary with generation parameters.\n            Used for fixed generation. Should follow exactly the same structure\n            and be of the same type as the returned generation parameters.\n            Can be used to replicate the augmentations (power)\n            used for the generation of a specific sample.\n    Returns:\n        Dictionaries with the generated data and the generation parameters.\n            First dictionary contains the `image`, `label` and the `name` keys.\n            The second dictionary contains the parameters used for the generation.\n\n    !!! Note\n        The `image` is scaled to `[0, 1]` and oriented with the `label` to **RAS**\n        and returned on the device  specified in the `generator` initialization.\n    \"\"\"\n    # use generation_params to track the parameters used for the generation\n    generation_params = {}\n\n    image = (\n        self.loader(\n            self.img_paths[idx], interp=\"linear\", spatial_size=192, resolution=1.0\n        )\n        if self.load_image\n        else None\n    )\n    segm = self.loader(\n        self.segm_paths[idx], interp=\"nearest\", spatial_size=192, resolution=1.0\n    )\n\n    # RANDOM re-orient TODO: MAKE SWTICHABLE!\n    # LR = \"L\" if torch.rand(1) &gt; 0.5 else \"R\"\n    # AP = \"A\" if torch.rand(1) &gt; 0.5 else \"P\"\n    # IS = \"I\" if torch.rand(1) &gt; 0.5 else \"S\"\n    # orient = np.array([LR, AP, IS])\n    # rand_orient_oreder = torch.randperm(3)\n    axcodes = \"RAS\"  # = orient[rand_orient_oreder]\n    orientation = Orientation(axcodes=axcodes)\n    image = orientation(image.unsqueeze(0)).squeeze(0) if self.load_image else None\n    segm = orientation(segm.unsqueeze(0)).squeeze(0)\n\n    # transform name into a single string otherwise collate fails\n    name = self.sub_ses[idx]\n    name = self._sub_ses_string(name[0], ses=name[1])\n\n    # initialize seeds as dictionary\n    # with paths to the seeds volumes\n    # or None if image is to be used as intensity prior\n    if self.seed_path is not None:\n        seeds = self.seed_paths[name]\n    if self.image_as_intensity:\n        seeds = None\n\n    # log input data\n    generation_params[\"idx\"] = idx\n    generation_params[\"img_paths\"] = str(self.img_paths[idx])\n    generation_params[\"segm_paths\"] = str(self.img_paths[idx])\n    generation_params[\"seeds\"] = str(self.seed_path)\n    generation_time_start = time.time()\n\n    # generate the synthetic data\n    gen_output, segmentation, image, synth_params = self.generator.sample(\n        image=image,\n        segmentation=segm,\n        seeds=seeds,\n        genparams=genparams,\n        orientation=orientation,\n    )\n\n    # scale the images to [0, 1]\n    gen_output = self.scaler(gen_output)\n    image = self.scaler(image) if image is not None else None\n\n    # ensure image and segmentation are on the cpu\n    gen_output = gen_output.cpu()\n    segmentation = segmentation.cpu()\n    image = image.cpu() if image is not None else None\n\n    generation_params = {**generation_params, **synth_params}\n    generation_params[\"generation_time\"] = time.time() - generation_time_start\n    data_out = {\n        \"image\": gen_output.unsqueeze(0),\n        \"label\": segmentation.unsqueeze(0).long(),\n    }\n\n    if self.transforms:\n        data_out = self.transforms(data_out)\n    data_out[\"name\"] = name\n\n    return data_out, generation_params\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalSynthDataset.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Retrieve a single item from the dataset at the specified index.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the item to retrieve.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with the <code>image</code>, <code>label</code> and the <code>name</code> keys. <code>image</code> and <code>label</code> are <code>torch.float32</code> <code>monai.data.meta_tensor.MetaTensor</code> and <code>name</code> is a string of a format <code>sub_ses</code> where <code>sub</code> is the subject name and <code>ses</code> is the session name.</p> <p>Note</p> <p>The <code>image</code> is scaled to <code>[0, 1]</code> and oriented to RAS and returned on the device specified in the <code>generator</code> initialization.</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>def __getitem__(self, idx) -&gt; dict:\n    \"\"\"\n    Retrieve a single item from the dataset at the specified index.\n\n    Args:\n        idx (int): The index of the item to retrieve.\n\n    Returns:\n        Dictionary with the `image`, `label` and the `name` keys.\n            `image` and `label` are `torch.float32`\n            [`monai.data.meta_tensor.MetaTensor`](https://docs.monai.io/en/stable/data.html#metatensor)\n            and `name` is a string of a format `sub_ses` where `sub` is the subject name\n            and `ses` is the session name.\n\n    !!!Note\n        The `image` is scaled to `[0, 1]` and oriented to **RAS** and returned on the device\n        specified in the `generator` initialization.\n    \"\"\"\n    data_out, generation_params = self.sample(idx)\n    self.generation_params = generation_params\n    return data_out\n</code></pre>"},{"location":"datasets/#fetalsyngen.data.datasets.FetalSynthDataset.sample_with_meta","title":"<code>sample_with_meta(idx, genparams={})</code>","text":"<p>Retrieve a sample along with its generation parameters and store them in the same dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the sample to retrieve.</p> required <code>genparams</code> <code>dict</code> <p>Dictionary with generation parameters. Used for fixed generation. Should follow exactly the same structure and be of the same type as the returned generation parameters from the <code>sample()</code> method. Can be used to replicate the augmentations (power) used for the generation of a specific sample.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with <code>image</code>, <code>label</code>, <code>name</code> and <code>generation_params</code> keys.</p> Source code in <code>fetalsyngen/data/datasets.py</code> <pre><code>def sample_with_meta(self, idx: int, genparams: dict = {}) -&gt; dict:\n    \"\"\"\n    Retrieve a sample along with its generation parameters\n    and store them in the same dictionary.\n\n    Args:\n        idx: The index of the sample to retrieve.\n        genparams: Dictionary with generation parameters.\n            Used for fixed generation. Should follow exactly the same structure\n            and be of the same type as the returned generation parameters from the `sample()` method.\n            Can be used to replicate the augmentations (power)\n            used for the generation of a specific sample.\n\n    Returns:\n        A dictionary with `image`, `label`, `name` and `generation_params` keys.\n    \"\"\"\n\n    data, generation_params = self.sample(idx, genparams=genparams)\n    data[\"generation_params\"] = generation_params\n    return data\n</code></pre>"},{"location":"datasets/#fixed-image-generation","title":"Fixed Image Generation","text":"<p>It is possible to generate synthetic images of the same 'augmentation' power as any given synthetic image. This is done by passing the <code>genparams</code> dictionary to the <code>sample_with_meta</code> (or <code>sample</code>) method of the <code>FetalSynthDataset</code> class. The <code>generation_params</code> dictionary is a dictionary of the parameters used to generate the image. The method will then use these parameters to generate a new image with the same <code>augmentation power</code> as the original image.</p> <p>This <code>genparams</code> dictionary can be obtained, for example, from the dictionary returned by the <code>FetalSynthDataset.sample_with_meta</code>  method. It then can be directly used to <code>fix</code> (some or all) generation parameters for the new image.</p> <p>See example below:</p> <pre><code># initialize the dataset class\n# see the Examples page for more details\ndataset = FetalSynthDataset(...)\n\n# first sample a synthetic image from the dataset\nsample = dataset.sample_with_meta(0)\n# then we sample a synthetic image with the same augmentation power as the first image\nsample_copy = dataset.sample_with_meta(0, genparams=sample[\"generation_params\"])\n</code></pre> <p>For example, generation parameters of the first image can be like this:</p> <pre><code>{'idx': 0,\n 'img_paths': PosixPath('../data/sub-sta38/anat/sub-sta38_rec-irtk_T2w.nii.gz'),\n 'segm_paths': PosixPath('../data/sub-sta38/anat/sub-sta38_rec-irtk_T2w.nii.gz'),\n 'seeds': defaultdict(dict,\n             {1: {1: PosixPath('../data/derivatives/seeds/subclasses_1/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_1.nii.gz'),\n               2: PosixPath('../data/derivatives/seeds/subclasses_1/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_2.nii.gz'),\n               3: PosixPath('../data/derivatives/seeds/subclasses_1/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_3.nii.gz'),\n               4: PosixPath('../data/derivatives/seeds/subclasses_1/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_4.nii.gz')},\n              2: {1: PosixPath('../data/derivatives/seeds/subclasses_2/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_1.nii.gz'),\n               2: PosixPath('../data/derivatives/seeds/subclasses_2/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_2.nii.gz'),\n               3: PosixPath('../data/derivatives/seeds/subclasses_2/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_3.nii.gz'),\n               4: PosixPath('../data/derivatives/seeds/subclasses_2/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_4.nii.gz')},\n              3: {1: PosixPath('../data/derivatives/seeds/subclasses_3/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_1.nii.gz'),\n               2: PosixPath('../data/derivatives/seeds/subclasses_3/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_2.nii.gz'),\n               3: PosixPath('../data/derivatives/seeds/subclasses_3/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_3.nii.gz'),\n               4: PosixPath('../data/derivatives/seeds/subclasses_3/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_4.nii.gz')}}),\n 'selected_seeds': {'mlabel2subclusters': {1: 2, 2: 1, 3: 3, 4: 1}},\n 'seed_intensities': {'mus': tensor([109.6722, 220.9658, 100.9801,  38.6364, 125.5148, 108.1950, 216.1060,\n          190.5462,  55.3930,  59.2667,  72.0628,  68.8775,  76.5113,  84.6639,\n           90.0124,  94.1701,  67.0610,  25.9465,  31.5438,  21.0375, 192.4223,\n          173.7434, 139.9284, 121.3904, 145.4289, 158.1318, 157.4630, 150.0894,\n          183.9047, 181.7129, 114.8939,   9.5253,  29.0257,  97.9543, 122.0798,\n           72.2969,  26.3086,  81.8050,  67.7463,  72.3737, 129.8539, 113.3900,\n          141.8177, 225.0000,  35.3458, 173.7635,  29.5101, 135.9482, 188.2391,\n          225.0000], device='cuda:0'),\n  'sigmas': tensor([ 9.2432, 23.1060, 16.4965,  6.4289, 24.7862, 23.7996, 15.2424, 20.2845,\n          12.6833,  6.9079,  6.1214, 22.1317,  9.7907,  5.5302, 14.3288, 11.1454,\n          16.0453, 20.9057, 24.2358, 13.4785, 22.7258, 11.2053, 12.9420, 13.4270,\n          14.8660, 22.4874,  5.6251,  9.8794,  8.8749, 19.0294,  9.7164,  6.2293,\n          13.6376, 11.7447, 14.1414,  6.4362, 20.4575, 14.6729,  8.4719, 14.2926,\n           6.9458, 11.5346, 14.6113,  6.6516, 22.1767,  8.3793, 20.1699,  6.3299,\n           5.3340, 21.8027], device='cuda:0')},\n 'deform_params': {'affine': {'rotations': array([ 0.0008224 ,  0.03067143, -0.0151502 ]),\n   'shears': array([-0.01735838,  0.00744726,  0.00012507]),\n   'scalings': array([1.09345725, 0.91695532, 0.98194215])},\n  'non_rigid': {'nonlin_scale': array([0.05686841]),\n   'nonlin_std': 1.048839010036788,\n   'size_F_small': [15, 15, 15]},\n  'flip': False},\n 'gamma_params': {'gamma': 0.960299468352801},\n 'bf_params': {'bf_scale': None, 'bf_std': None, 'bf_size': None},\n 'resample_params': {'spacing': array([0.65685245, 0.65685245, 0.65685245])},\n 'noise_params': {'noise_std': None},\n 'generation_time': 0.5615839958190918}\n</code></pre> <p> If the <code>key:value</code> pair exists in the passed <code>genparams</code> dictionary, the <code>sample</code> method will use directly the value from the <code>genparams</code> dictionary. If the <code>key:value</code> pair does not exist in the <code>genparams</code> dictionary or it is <code>None</code>,  <code>sample</code> method will generate the value randomly, using the corresponding class attributes.</p> <p>See how the keys <code>bf_scale</code>, <code>bf_std</code>, <code>bf_size</code> and <code>noise_std</code> have not been defined in the <code>genparams</code> dictionary above. This means that the <code>sample</code> method will generate these values randomly. The same could have been achieved by not passing them at all.</p>      {'idx': 0,     'img_paths': PosixPath('../data/sub-sta38/anat/sub-sta38_rec-irtk_T2w.nii.gz'),     'segm_paths': PosixPath('../data/sub-sta38/anat/sub-sta38_rec-irtk_T2w.nii.gz'),     'seeds': defaultdict(dict,                 {1: {1: PosixPath('../data/derivatives/seeds/subclasses_1/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_1.nii.gz'),                 2: PosixPath('../data/derivatives/seeds/subclasses_1/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_2.nii.gz'),                 3: PosixPath('../data/derivatives/seeds/subclasses_1/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_3.nii.gz'),                 4: PosixPath('../data/derivatives/seeds/subclasses_1/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_4.nii.gz')},                 2: {1: PosixPath('../data/derivatives/seeds/subclasses_2/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_1.nii.gz'),                 2: PosixPath('../data/derivatives/seeds/subclasses_2/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_2.nii.gz'),                 3: PosixPath('../data/derivatives/seeds/subclasses_2/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_3.nii.gz'),                 4: PosixPath('../data/derivatives/seeds/subclasses_2/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_4.nii.gz')},                 3: {1: PosixPath('../data/derivatives/seeds/subclasses_3/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_1.nii.gz'),                 2: PosixPath('../data/derivatives/seeds/subclasses_3/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_2.nii.gz'),                 3: PosixPath('../data/derivatives/seeds/subclasses_3/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_3.nii.gz'),                 4: PosixPath('../data/derivatives/seeds/subclasses_3/sub-sta38/anat/sub-sta38_rec-irtk_T2w_dseg_mlabel_4.nii.gz')}}),     'selected_seeds': {'mlabel2subclusters': {1: 2, 2: 1, 3: 3, 4: 1}},     'seed_intensities': {'mus': tensor([109.6722, 220.9658, 100.9801,  38.6364, 125.5148, 108.1950, 216.1060,             190.5462,  55.3930,  59.2667,  72.0628,  68.8775,  76.5113,  84.6639,             90.0124,  94.1701,  67.0610,  25.9465,  31.5438,  21.0375, 192.4223,             173.7434, 139.9284, 121.3904, 145.4289, 158.1318, 157.4630, 150.0894,             183.9047, 181.7129, 114.8939,   9.5253,  29.0257,  97.9543, 122.0798,             72.2969,  26.3086,  81.8050,  67.7463,  72.3737, 129.8539, 113.3900,             141.8177, 225.0000,  35.3458, 173.7635,  29.5101, 135.9482, 188.2391,             225.0000], device='cuda:0'),     'sigmas': tensor([ 9.2432, 23.1060, 16.4965,  6.4289, 24.7862, 23.7996, 15.2424, 20.2845,             12.6833,  6.9079,  6.1214, 22.1317,  9.7907,  5.5302, 14.3288, 11.1454,             16.0453, 20.9057, 24.2358, 13.4785, 22.7258, 11.2053, 12.9420, 13.4270,             14.8660, 22.4874,  5.6251,  9.8794,  8.8749, 19.0294,  9.7164,  6.2293,             13.6376, 11.7447, 14.1414,  6.4362, 20.4575, 14.6729,  8.4719, 14.2926,             6.9458, 11.5346, 14.6113,  6.6516, 22.1767,  8.3793, 20.1699,  6.3299,             5.3340, 21.8027], device='cuda:0')},     'deform_params': {'affine': {'rotations': array([ 0.0008224 ,  0.03067143, -0.0151502 ]),     'shears': array([-0.01735838,  0.00744726,  0.00012507]),     'scalings': array([1.09345725, 0.91695532, 0.98194215])},     'non_rigid': {'nonlin_scale': array([0.05686841]),     'nonlin_std': 1.048839010036788,     'size_F_small': [15, 15, 15]},     'flip': False},     'gamma_params': {'gamma': 0.960299468352801},     'bf_params': {'bf_scale': array([0.00797334]),     'bf_std': array([0.21896995]),     'bf_size': [2, 2, 2]},     'resample_params': {'spacing': array([0.65685245, 0.65685245, 0.65685245])},     'noise_params': {'noise_std': None},     'generation_time': 0.6192283630371094}     ```   <p></p> <p>Note</p> <ul> <li> <p>If a specific parameter is passed in <code>genparams</code> it means that the probability of its application is 100%. The internal <code>prob</code> is not used as the parameter is fixed.</p> </li> <li> <p>If using custom values for the parameters, ensure that the values are within the range of the parameters defined in the class attributes (especially for the spatial deformation parameters, as the grid is pre-defined at class initialization). Furthermore, ensure that the device location and parameter type is consistent with the one in the returned generation_parameters dictionary.</p> </li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>After installing the package, you can directly use the generator and datasets in your project. See the following examples for guidance on how to instantiate the generator and datasets.</p>"},{"location":"examples/#recommended-using-configuration-files","title":"Recommended: Using Configuration Files","text":"<p>For reproducibility and greater flexibility, we recommend using the configuration files provided in the package. These files define the parameters for the generator and datasets, allowing for quick and easy setup with <code>hydra</code>.</p>"},{"location":"examples/#steps-to-use-configuration-files","title":"Steps to Use Configuration Files","text":"<ol> <li>Copy the configuration files (entire <code>configs/dataset</code> folder) to your project root directory into <code>configs/dataset</code>.</li> <li>Use the following methods to instantiate the generator and dataset classes:</li> </ol> <p>For examples below, set up <code>cfg_path = \"configs/dataset\"</code> as the path to the configuration files and <code>cfg_name</code> as the name of the configuration file you want to use (<code>cfg_name='synth_train'</code> for example for the synthetic training dataset).</p> <p>See the <code>Configs</code> page for detailed information on configuration files and available generation modes.</p>   Using the Imperative API  <pre><code>import hydra\n\nwith hydra.initialize(config_path=cfg_path, version_base=\"1.2\"):\n    cfg = hydra.compose(config_name=cfg_name)\n    print(f\"Composed config: {cfg}\")\n    dataset = hydra.utils.instantiate(cfg)\n</code></pre>  Using the Declarative API  <pre><code>import hydra\nfrom omegaconf import DictConfig\n\n@hydra.main(config_path=cfg_path, config_name=cfg_name)\ndef my_app(cfg: DictConfig) -&gt; None:\n    print(cfg)\n</code></pre> <p></p> <p>Note</p> <p>Ensure that the <code>bids</code> and <code>seeds</code> paths in the configuration files are updated to the absolute paths for your data.</p>"},{"location":"examples/#using-direct-instantiation","title":"Using Direct Instantiation","text":"<p>You can manually instantiate required classes from the <code>FetalSynthGen</code> in your project as needed. For example, to instantiate the <code>FetalSynthDataset</code> class and generator components follow the example below:</p> <pre><code># Import necessary classes\nfrom fetalsyngen.data.datasets import FetalSynthDataset\n\nfrom fetalsyngen.generator.model import FetalSynthGen\nfrom fetalsyngen.generator.augmentation.synthseg import (\n    RandBiasField,\n    RandGamma,\n    RandNoise,\n    RandResample,\n)\nfrom fetalsyngen.generator.deformation.affine_nonrigid import SpatialDeformation\nfrom fetalsyngen.generator.intensity.rand_gmm import ImageFromSeeds\n\n# Instantiate the generator components\nintensity_generator = ImageFromSeeds(\n    min_subclusters=1,\n    max_subclusters=3,\n    seed_labels=[1, 2, 3, 4, 5],\n    generation_classes=[1, 2, 3, 4, 5],\n    meta_labels=4,\n)\nspatial_deform = SpatialDeformation(\n    max_rotation=10,\n    max_shear=1,\n    max_scaling=1,\n    size=(256, 256, 256),\n    nonlinear_transform=1,\n    nonlin_scale_min=1,\n    nonlin_scale_max=1,\n    nonlin_std_max=1,\n    flip_prb=1,\n    device=\"cuda\",\n)\nresampler = RandResample(prob=0.5, max_resolution=1.5, min_resolution=0.5)\nbias_field = RandBiasField(\n    prob=0.5, scale_min=0.5, scale_max=1.5, std_min=0.5, std_max=1.5\n)\nnoise = RandNoise(prob=0.5, std_min=0.5, std_max=1.5)\ngamma = RandGamma(prob=0.5, gamma_std=0.5)\n\n# Instantiate the generator\ngenerator = FetalSynthGen(\n    shape=(256, 256, 256),\n    resolution=(0.5, 0.5, 0.5),\n    device=\"cuda\",\n    intensity_generator=intensity_generator,\n    spatial_deform=spatial_deform,\n    resampler=resampler,\n    bias_field=bias_field,\n    noise=noise,\n    gamma=gamma,\n)\n\n# Instantiate the dataset\ndataset = FetalSynthDataset(\n    bids_path=\"./../../data\",\n    generator=generator,\n    seed_path=\"./../../data/derivatives/seeds\",\n    sub_list=None,\n)\n</code></pre> <p></p>"},{"location":"examples/#additional-resources","title":"Additional Resources","text":"<p>For more examples of generator instantiation with <code>hydra</code>, see the <code>Generator Instantiation</code> notebook.</p>"},{"location":"generation/","title":"Generation","text":""},{"location":"generation/#api","title":"API","text":""},{"location":"generation/#fetalsyngen.generator.model.FetalSynthGen","title":"<code>FetalSynthGen</code>","text":"Source code in <code>fetalsyngen/generator/model.py</code> <pre><code>class FetalSynthGen:\n\n    def __init__(\n        self,\n        shape: Iterable[int],\n        resolution: Iterable[float],\n        device: str,\n        intensity_generator: ImageFromSeeds,\n        spatial_deform: SpatialDeformation,\n        resampler: RandResample,\n        bias_field: RandBiasField,\n        noise: RandNoise,\n        gamma: RandGamma,\n        # optional SR artifacts\n        blur_cortex: BlurCortex | None = None,\n        struct_noise: StructNoise | None = None,\n        simulate_motion: SimulateMotion | None = None,\n        boundaries: SimulatedBoundaries | None = None,\n        # optional\n        stack_sampler: StackSampler | None = None,\n    ):\n        \"\"\"\n        Initialize the model with the given parameters.\n\n        !!!Note\n            Augmentations related to SR artifacts are optional and can be set to None\n            if not needed.\n\n        Args:\n            shape: Shape of the output image.\n            resolution: Resolution of the output image.\n            device: Device to use for computation.\n            intensity_generator: Intensity generator.\n            spatial_deform: Spatial deformation generator.\n            resampler: Resampler.\n            bias_field: Bias field generator.\n            noise: Noise generator.\n            gamma: Gamma correction generator.\n            blur_cortex: Cortex blurring generator.\n            struct_noise: Structural noise generator.\n            simulate_motion: Motion simulation generator.\n            boundaries: Boundaries generator\n            stack_sampler: Stack sampler.\n\n        \"\"\"\n        self.shape = shape\n        self.resolution = resolution\n        self.intensity_generator = intensity_generator\n        self.spatial_deform = spatial_deform\n        self.resampled = resampler\n        self.biasfield = bias_field\n        self.gamma = gamma\n        self.noise = noise\n\n        self.artifacts = {\n            \"blur_cortex\": blur_cortex,\n            \"struct_noise\": struct_noise,\n            \"simulate_motion\": simulate_motion,\n            \"boundaries\": boundaries,\n        }\n        self.stack_sampler = stack_sampler\n        self.device = device\n\n    def _validated_genparams(self, d: dict) -&gt; dict:\n        \"\"\"Recursively removes all the keys with None values as they are not fixed in the generation.\"\"\"\n        if not isinstance(d, dict):\n            return d  # Return non-dictionaries as-is\n\n        return {\n            key: self._validated_genparams(value)\n            for key, value in d.items()\n            if value is not None\n        }\n\n    def sample(\n        self,\n        orientation,\n        image: torch.Tensor | None,\n        segmentation: torch.Tensor,\n        seeds: torch.Tensor | None,\n        genparams: dict = {},\n    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, dict]:\n        \"\"\"\n        Generate a synthetic image from the input data.\n        Supports both random generation and from a fixed genparams dictionary.\n\n        Args:\n            image: Image to use as intensity prior if required.\n            segmentation: Segmentation to use as spatial prior.\n            seeds: Seeds to use for intensity generation.\n            genparams: Dictionary with generation parameters.\n                Used for fixed generation.\n                Should follow the structure and be of the same type as\n                the returned generation parameters.\n\n        Returns:\n            The synthetic image, the segmentation, the original image, and the generation parameters.\n\n        \"\"\"\n        if genparams:\n            genparams = self._validated_genparams(genparams)\n\n        # 1. Generate intensity output.\n        if seeds is not None:\n            seeds, selected_seeds = self.intensity_generator.load_seeds(\n                seeds=seeds,\n                genparams=genparams.get(\"selected_seeds\", {}),\n                orientation=orientation,\n            )\n            output, seed_intensities = self.intensity_generator.sample_intensities(\n                seeds=seeds,\n                device=self.device,\n                genparams=genparams.get(\"seed_intensities\", {}),\n            )\n        else:\n            if image is None:\n                raise ValueError(\n                    \"If no seeds are passed, an image must be loaded to be used as intensity prior!\"\n                )\n            # normalize the image from 0 to 255 to\n            # match the intensity generator\n            output = (image - image.min()) / (image.max() - image.min()) * 255\n            selected_seeds = {}\n            seed_intensities = {}\n\n        # ensure that tensors are on the same device\n        output = output.to(self.device)\n        segmentation = segmentation.to(self.device)\n        image = image.to(self.device) if image is not None else None\n\n        # 2. Spatially deform the data\n        image, segmentation, output, deform_params = self.spatial_deform.deform(\n            image=image,\n            segmentation=segmentation,\n            output=output,\n            genparams=genparams.get(\"deform_params\", {}),\n        )\n\n        # 3. Gamma contrast transformation\n        output, gamma_params = self.gamma(\n            output, self.device, genparams=genparams.get(\"gamma_params\", {})\n        )\n\n        # 4. Bias field corruption\n        output, bf_params = self.biasfield(\n            output, self.device, genparams=genparams.get(\"bf_params\", {})\n        )\n\n        # 5. Downsample to simulate lower reconstruction resolution\n        output, factors, resample_params = self.resampled(\n            output,\n            np.array(self.resolution),\n            self.device,\n            genparams=genparams.get(\"resample_params\", {}),\n        )\n\n        # 6. Noise corruption\n        output, noise_params = self.noise(\n            output, self.device, genparams=genparams.get(\"noise_params\", {})\n        )\n\n        # 7. Up-sample back to the original resolution/shape\n        output = self.resampled.resize_back(output, factors)\n\n        # 8. Induce SR-artifacts\n        artifacts = {}\n        for name, artifact in self.artifacts.items():\n            if artifact is not None:\n                output, metadata = artifact(\n                    output,\n                    segmentation,\n                    self.device,\n                    genparams.get(\"artifact_params\", {}),\n                    resolution=self.resolution,\n                )\n                artifacts[name] = metadata\n\n        # 9. Apply stack sampler if available\n        if self.stack_sampler is not None:\n            output, segmentation, meta = self.stack_sampler(\n                output, segmentation, device=self.device\n            )\n\n            # unsqueeze the image to match the expected shape\n            output = output.squeeze(0)\n            segmentation = segmentation.squeeze(0)\n\n        # 10. Aggregete the synth params\n        synth_params = {\n            \"selected_seeds\": selected_seeds,\n            \"seed_intensities\": seed_intensities,\n            \"deform_params\": deform_params,\n            \"gamma_params\": gamma_params,\n            \"bf_params\": bf_params,\n            \"resample_params\": resample_params,\n            \"noise_params\": noise_params,\n            \"artifacts\": artifacts,\n            \"stack_sampler\": meta if self.stack_sampler is not None else None,\n        }\n\n        return output, segmentation, image, synth_params\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.model.FetalSynthGen.__init__","title":"<code>__init__(shape, resolution, device, intensity_generator, spatial_deform, resampler, bias_field, noise, gamma, blur_cortex=None, struct_noise=None, simulate_motion=None, boundaries=None, stack_sampler=None)</code>","text":"<p>Initialize the model with the given parameters.</p> <p>Note</p> <p>Augmentations related to SR artifacts are optional and can be set to None if not needed.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Iterable[int]</code> <p>Shape of the output image.</p> required <code>resolution</code> <code>Iterable[float]</code> <p>Resolution of the output image.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>intensity_generator</code> <code>ImageFromSeeds</code> <p>Intensity generator.</p> required <code>spatial_deform</code> <code>SpatialDeformation</code> <p>Spatial deformation generator.</p> required <code>resampler</code> <code>RandResample</code> <p>Resampler.</p> required <code>bias_field</code> <code>RandBiasField</code> <p>Bias field generator.</p> required <code>noise</code> <code>RandNoise</code> <p>Noise generator.</p> required <code>gamma</code> <code>RandGamma</code> <p>Gamma correction generator.</p> required <code>blur_cortex</code> <code>BlurCortex | None</code> <p>Cortex blurring generator.</p> <code>None</code> <code>struct_noise</code> <code>StructNoise | None</code> <p>Structural noise generator.</p> <code>None</code> <code>simulate_motion</code> <code>SimulateMotion | None</code> <p>Motion simulation generator.</p> <code>None</code> <code>boundaries</code> <code>SimulatedBoundaries | None</code> <p>Boundaries generator</p> <code>None</code> <code>stack_sampler</code> <code>StackSampler | None</code> <p>Stack sampler.</p> <code>None</code> Source code in <code>fetalsyngen/generator/model.py</code> <pre><code>def __init__(\n    self,\n    shape: Iterable[int],\n    resolution: Iterable[float],\n    device: str,\n    intensity_generator: ImageFromSeeds,\n    spatial_deform: SpatialDeformation,\n    resampler: RandResample,\n    bias_field: RandBiasField,\n    noise: RandNoise,\n    gamma: RandGamma,\n    # optional SR artifacts\n    blur_cortex: BlurCortex | None = None,\n    struct_noise: StructNoise | None = None,\n    simulate_motion: SimulateMotion | None = None,\n    boundaries: SimulatedBoundaries | None = None,\n    # optional\n    stack_sampler: StackSampler | None = None,\n):\n    \"\"\"\n    Initialize the model with the given parameters.\n\n    !!!Note\n        Augmentations related to SR artifacts are optional and can be set to None\n        if not needed.\n\n    Args:\n        shape: Shape of the output image.\n        resolution: Resolution of the output image.\n        device: Device to use for computation.\n        intensity_generator: Intensity generator.\n        spatial_deform: Spatial deformation generator.\n        resampler: Resampler.\n        bias_field: Bias field generator.\n        noise: Noise generator.\n        gamma: Gamma correction generator.\n        blur_cortex: Cortex blurring generator.\n        struct_noise: Structural noise generator.\n        simulate_motion: Motion simulation generator.\n        boundaries: Boundaries generator\n        stack_sampler: Stack sampler.\n\n    \"\"\"\n    self.shape = shape\n    self.resolution = resolution\n    self.intensity_generator = intensity_generator\n    self.spatial_deform = spatial_deform\n    self.resampled = resampler\n    self.biasfield = bias_field\n    self.gamma = gamma\n    self.noise = noise\n\n    self.artifacts = {\n        \"blur_cortex\": blur_cortex,\n        \"struct_noise\": struct_noise,\n        \"simulate_motion\": simulate_motion,\n        \"boundaries\": boundaries,\n    }\n    self.stack_sampler = stack_sampler\n    self.device = device\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.model.FetalSynthGen.sample","title":"<code>sample(orientation, image, segmentation, seeds, genparams={})</code>","text":"<p>Generate a synthetic image from the input data. Supports both random generation and from a fixed genparams dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Tensor | None</code> <p>Image to use as intensity prior if required.</p> required <code>segmentation</code> <code>Tensor</code> <p>Segmentation to use as spatial prior.</p> required <code>seeds</code> <code>Tensor | None</code> <p>Seeds to use for intensity generation.</p> required <code>genparams</code> <code>dict</code> <p>Dictionary with generation parameters. Used for fixed generation. Should follow the structure and be of the same type as the returned generation parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor, Tensor, dict]</code> <p>The synthetic image, the segmentation, the original image, and the generation parameters.</p> Source code in <code>fetalsyngen/generator/model.py</code> <pre><code>def sample(\n    self,\n    orientation,\n    image: torch.Tensor | None,\n    segmentation: torch.Tensor,\n    seeds: torch.Tensor | None,\n    genparams: dict = {},\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, dict]:\n    \"\"\"\n    Generate a synthetic image from the input data.\n    Supports both random generation and from a fixed genparams dictionary.\n\n    Args:\n        image: Image to use as intensity prior if required.\n        segmentation: Segmentation to use as spatial prior.\n        seeds: Seeds to use for intensity generation.\n        genparams: Dictionary with generation parameters.\n            Used for fixed generation.\n            Should follow the structure and be of the same type as\n            the returned generation parameters.\n\n    Returns:\n        The synthetic image, the segmentation, the original image, and the generation parameters.\n\n    \"\"\"\n    if genparams:\n        genparams = self._validated_genparams(genparams)\n\n    # 1. Generate intensity output.\n    if seeds is not None:\n        seeds, selected_seeds = self.intensity_generator.load_seeds(\n            seeds=seeds,\n            genparams=genparams.get(\"selected_seeds\", {}),\n            orientation=orientation,\n        )\n        output, seed_intensities = self.intensity_generator.sample_intensities(\n            seeds=seeds,\n            device=self.device,\n            genparams=genparams.get(\"seed_intensities\", {}),\n        )\n    else:\n        if image is None:\n            raise ValueError(\n                \"If no seeds are passed, an image must be loaded to be used as intensity prior!\"\n            )\n        # normalize the image from 0 to 255 to\n        # match the intensity generator\n        output = (image - image.min()) / (image.max() - image.min()) * 255\n        selected_seeds = {}\n        seed_intensities = {}\n\n    # ensure that tensors are on the same device\n    output = output.to(self.device)\n    segmentation = segmentation.to(self.device)\n    image = image.to(self.device) if image is not None else None\n\n    # 2. Spatially deform the data\n    image, segmentation, output, deform_params = self.spatial_deform.deform(\n        image=image,\n        segmentation=segmentation,\n        output=output,\n        genparams=genparams.get(\"deform_params\", {}),\n    )\n\n    # 3. Gamma contrast transformation\n    output, gamma_params = self.gamma(\n        output, self.device, genparams=genparams.get(\"gamma_params\", {})\n    )\n\n    # 4. Bias field corruption\n    output, bf_params = self.biasfield(\n        output, self.device, genparams=genparams.get(\"bf_params\", {})\n    )\n\n    # 5. Downsample to simulate lower reconstruction resolution\n    output, factors, resample_params = self.resampled(\n        output,\n        np.array(self.resolution),\n        self.device,\n        genparams=genparams.get(\"resample_params\", {}),\n    )\n\n    # 6. Noise corruption\n    output, noise_params = self.noise(\n        output, self.device, genparams=genparams.get(\"noise_params\", {})\n    )\n\n    # 7. Up-sample back to the original resolution/shape\n    output = self.resampled.resize_back(output, factors)\n\n    # 8. Induce SR-artifacts\n    artifacts = {}\n    for name, artifact in self.artifacts.items():\n        if artifact is not None:\n            output, metadata = artifact(\n                output,\n                segmentation,\n                self.device,\n                genparams.get(\"artifact_params\", {}),\n                resolution=self.resolution,\n            )\n            artifacts[name] = metadata\n\n    # 9. Apply stack sampler if available\n    if self.stack_sampler is not None:\n        output, segmentation, meta = self.stack_sampler(\n            output, segmentation, device=self.device\n        )\n\n        # unsqueeze the image to match the expected shape\n        output = output.squeeze(0)\n        segmentation = segmentation.squeeze(0)\n\n    # 10. Aggregete the synth params\n    synth_params = {\n        \"selected_seeds\": selected_seeds,\n        \"seed_intensities\": seed_intensities,\n        \"deform_params\": deform_params,\n        \"gamma_params\": gamma_params,\n        \"bf_params\": bf_params,\n        \"resample_params\": resample_params,\n        \"noise_params\": noise_params,\n        \"artifacts\": artifacts,\n        \"stack_sampler\": meta if self.stack_sampler is not None else None,\n    }\n\n    return output, segmentation, image, synth_params\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.intensity.rand_gmm.ImageFromSeeds","title":"<code>ImageFromSeeds</code>","text":"Source code in <code>fetalsyngen/generator/intensity/rand_gmm.py</code> <pre><code>class ImageFromSeeds:\n\n    def __init__(\n        self,\n        min_subclusters: int,\n        max_subclusters: int,\n        seed_labels: Iterable[int],\n        generation_classes: Iterable[int],\n        meta_labels: list[int] = [1, 2, 3, 4],\n    ):\n        \"\"\"\n\n        Args:\n            min_subclusters (int): Minimum number of subclusters to use.\n            max_subclusters (int): Maximum number of subclusters to use.\n            seed_labels (Iterable[int]): Iterable with all possible labels\n                that can occur in the loaded seeds. Should be a unique set of\n                integers starting from [0, ...]. 0 is reserved for the background,\n                that will not have any intensity generated.\n            generation_classes (Iterable[int]): Classes to use for generation.\n                Seeds with the same generation calss will be generated with\n                the same GMM. Should be the same length as seed_labels.\n            meta_labels (int, optional): Number of meta-labels used. Defaults to 4.\n        \"\"\"\n        self.min_subclusters = min_subclusters\n        self.max_subclusters = max_subclusters\n        try:\n            assert len(set(seed_labels)) == len(seed_labels)\n        except AssertionError:\n            raise ValueError(\"Parameter seed_labels should have unique values.\")\n        try:\n            assert len(seed_labels) == len(generation_classes)\n        except AssertionError:\n            raise ValueError(\n                \"Parameters seed_labels and generation_classes should have the same lengths.\"\n            )\n        self.seed_labels = seed_labels\n        self.generation_classes = generation_classes\n        self.meta_labels = meta_labels\n        self.loader = SimpleITKReader()\n\n    def load_seeds(\n        self,\n        seeds: dict[int : dict[int:Path]],\n        mlabel2subclusters: dict[int:int] | None = None,\n        genparams: dict = {},\n        orientation: Orientation = Orientation(\"RAS\"),\n    ) -&gt; torch.Tensor:\n        \"\"\"Generate an intensity image from seeds.\n        If seed_mapping is provided, it is used to\n        select the number of subclusters to use for\n        each meta label. Otherwise, the number of subclusters\n        is randomly selected from a uniform discrete distribution\n        between `min_subclusters` and `max_subclusters` (both inclusive).\n\n        Args:\n\n            seeds: Dictionary with the mapping `subcluster_number: {meta_label: seed_path}`.\n            mlabel2subclusters: Mapping to use when defining how many subclusters to\n                use for each meta-label. Defaults to None.\n            genparams: Dictionary with generation parameters. Defaults to {}.\n                Should contain the key \"mlabel2subclusters\" if the mapping is to be fixed.\n            orientation: Orientation to use. Defaults to Orientation(\"RAS\").\n\n\n        Returns:\n            torch.Tensor: Intensity image with the same shape as the seeds.\n                Tensor dimensions are **(H, W, D)**. Values inside the tensor\n                correspond to the subclusters, and are grouped by meta-label.\n                `1-19: CSF, 20-29: GM, 30-39: WM, 40-49: Extra-cerebral`.\n        \"\"\"\n        # if no mapping is provided, randomly select the number of subclusters\n        # to use for each meta-label in the format {mlabel: n_subclusters}\n        if mlabel2subclusters is None:\n            mlabel2subclusters = {\n                meta_label: np.random.randint(\n                    self.min_subclusters, self.max_subclusters + 1\n                )\n                for meta_label in self.meta_labels\n            }\n        if \"mlabel2subclusters\" in genparams.keys():\n            mlabel2subclusters = genparams[\"mlabel2subclusters\"]\n\n        # load the first seed as the one corresponding to mlabel 1\n        first_mlab = list(mlabel2subclusters.keys())[0]\n        first_subcls = list(seeds[mlabel2subclusters[first_mlab]].keys())[0]\n\n        seed = self.loader(\n            seeds[mlabel2subclusters[first_mlab]][first_subcls],\n            interp=\"nearest\",\n            spatial_size=192,\n            resolution=1.0,\n        )\n        seed = orientation(seed.unsqueeze(0))\n        #\n        # re-orient seeds to RAS\n        for mlabel in self.meta_labels:\n            if mlabel == first_mlab:\n                continue\n            new_seed = self.loader(\n                seeds[mlabel2subclusters[mlabel]][mlabel],\n                interp=\"nearest\",\n                spatial_size=192,\n                resolution=1.0,\n            )\n            new_seed = orientation(new_seed.unsqueeze(0))\n            seed += new_seed\n\n        return seed.long().squeeze(0), {\"mlabel2subclusters\": mlabel2subclusters}\n\n    def sample_intensities(\n        self, seeds: torch.Tensor, device: str, genparams: dict = {}\n    ) -&gt; torch.Tensor:\n        \"\"\"Sample the intensities from the seeds.\n\n        Args:\n            seeds (torch.Tensor): Tensor with the seeds.\n            device (str): Device to use. Should be \"cuda\" or \"cpu\".\n            genparams (dict, optional): Dictionary with generation parameters.\n                Defaults to {}. Should contain the keys \"mus\" and \"sigmas\" if\n                the GMM parameters are to be fixed.\n\n        Returns:\n            torch.Tensor: Tensor with the intensities.\n        \"\"\"\n        nlabels = max(self.seed_labels) + 1\n        nsamp = len(self.seed_labels)\n\n        # # Sample GMMs means and stds\n        mus = (\n            25 + 200 * torch.rand(nlabels, dtype=torch.float, device=device)\n            if \"mus\" not in genparams.keys()\n            else genparams[\"mus\"]\n        )\n        sigmas = (\n            5\n            + 20\n            * torch.rand(\n                nlabels,\n                dtype=torch.float,\n                device=device,\n            )\n            if \"sigmas\" not in genparams.keys()\n            else genparams[\"sigmas\"]\n        )\n\n        # if there are seed labels from the same generation class\n        # set their mean to be the same with some random perturbation\n        if self.generation_classes != self.seed_labels:\n            # Ensure that seeds are within valid range\n            if (seeds &lt; 0).any() or (seeds &gt;= mus.size(0)).any():\n                raise ValueError(\n                    f\"Invalid seed indices detected: min={seeds.min().item()}, max={seeds.max().item()} (expected range: 0-{mus.size(0)-1})\"\n                )\n\n            mus[self.seed_labels] = torch.clamp(\n                mus[self.generation_classes]\n                + 25 * torch.randn(nsamp, dtype=torch.float, device=device),\n                0,\n                225,\n            )\n        intensity_image = mus[seeds] + sigmas[seeds] * torch.randn(\n            seeds.shape, dtype=torch.float, device=device\n        )\n        intensity_image[intensity_image &lt; 0] = 0\n\n        return intensity_image, {\n            \"mus\": mus,\n            \"sigmas\": sigmas,\n        }\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.intensity.rand_gmm.ImageFromSeeds.__init__","title":"<code>__init__(min_subclusters, max_subclusters, seed_labels, generation_classes, meta_labels=[1, 2, 3, 4])</code>","text":"<p>Parameters:</p> Name Type Description Default <code>min_subclusters</code> <code>int</code> <p>Minimum number of subclusters to use.</p> required <code>max_subclusters</code> <code>int</code> <p>Maximum number of subclusters to use.</p> required <code>seed_labels</code> <code>Iterable[int]</code> <p>Iterable with all possible labels that can occur in the loaded seeds. Should be a unique set of integers starting from [0, ...]. 0 is reserved for the background, that will not have any intensity generated.</p> required <code>generation_classes</code> <code>Iterable[int]</code> <p>Classes to use for generation. Seeds with the same generation calss will be generated with the same GMM. Should be the same length as seed_labels.</p> required <code>meta_labels</code> <code>int</code> <p>Number of meta-labels used. Defaults to 4.</p> <code>[1, 2, 3, 4]</code> Source code in <code>fetalsyngen/generator/intensity/rand_gmm.py</code> <pre><code>def __init__(\n    self,\n    min_subclusters: int,\n    max_subclusters: int,\n    seed_labels: Iterable[int],\n    generation_classes: Iterable[int],\n    meta_labels: list[int] = [1, 2, 3, 4],\n):\n    \"\"\"\n\n    Args:\n        min_subclusters (int): Minimum number of subclusters to use.\n        max_subclusters (int): Maximum number of subclusters to use.\n        seed_labels (Iterable[int]): Iterable with all possible labels\n            that can occur in the loaded seeds. Should be a unique set of\n            integers starting from [0, ...]. 0 is reserved for the background,\n            that will not have any intensity generated.\n        generation_classes (Iterable[int]): Classes to use for generation.\n            Seeds with the same generation calss will be generated with\n            the same GMM. Should be the same length as seed_labels.\n        meta_labels (int, optional): Number of meta-labels used. Defaults to 4.\n    \"\"\"\n    self.min_subclusters = min_subclusters\n    self.max_subclusters = max_subclusters\n    try:\n        assert len(set(seed_labels)) == len(seed_labels)\n    except AssertionError:\n        raise ValueError(\"Parameter seed_labels should have unique values.\")\n    try:\n        assert len(seed_labels) == len(generation_classes)\n    except AssertionError:\n        raise ValueError(\n            \"Parameters seed_labels and generation_classes should have the same lengths.\"\n        )\n    self.seed_labels = seed_labels\n    self.generation_classes = generation_classes\n    self.meta_labels = meta_labels\n    self.loader = SimpleITKReader()\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.intensity.rand_gmm.ImageFromSeeds.load_seeds","title":"<code>load_seeds(seeds, mlabel2subclusters=None, genparams={}, orientation=Orientation('RAS'))</code>","text":"<p>Generate an intensity image from seeds. If seed_mapping is provided, it is used to select the number of subclusters to use for each meta label. Otherwise, the number of subclusters is randomly selected from a uniform discrete distribution between <code>min_subclusters</code> and <code>max_subclusters</code> (both inclusive).</p> <p>Args:</p> <pre><code>seeds: Dictionary with the mapping `subcluster_number: {meta_label: seed_path}`.\nmlabel2subclusters: Mapping to use when defining how many subclusters to\n    use for each meta-label. Defaults to None.\ngenparams: Dictionary with generation parameters. Defaults to {}.\n    Should contain the key \"mlabel2subclusters\" if the mapping is to be fixed.\norientation: Orientation to use. Defaults to Orientation(\"RAS\").\n</code></pre> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Intensity image with the same shape as the seeds. Tensor dimensions are (H, W, D). Values inside the tensor correspond to the subclusters, and are grouped by meta-label. <code>1-19: CSF, 20-29: GM, 30-39: WM, 40-49: Extra-cerebral</code>.</p> Source code in <code>fetalsyngen/generator/intensity/rand_gmm.py</code> <pre><code>def load_seeds(\n    self,\n    seeds: dict[int : dict[int:Path]],\n    mlabel2subclusters: dict[int:int] | None = None,\n    genparams: dict = {},\n    orientation: Orientation = Orientation(\"RAS\"),\n) -&gt; torch.Tensor:\n    \"\"\"Generate an intensity image from seeds.\n    If seed_mapping is provided, it is used to\n    select the number of subclusters to use for\n    each meta label. Otherwise, the number of subclusters\n    is randomly selected from a uniform discrete distribution\n    between `min_subclusters` and `max_subclusters` (both inclusive).\n\n    Args:\n\n        seeds: Dictionary with the mapping `subcluster_number: {meta_label: seed_path}`.\n        mlabel2subclusters: Mapping to use when defining how many subclusters to\n            use for each meta-label. Defaults to None.\n        genparams: Dictionary with generation parameters. Defaults to {}.\n            Should contain the key \"mlabel2subclusters\" if the mapping is to be fixed.\n        orientation: Orientation to use. Defaults to Orientation(\"RAS\").\n\n\n    Returns:\n        torch.Tensor: Intensity image with the same shape as the seeds.\n            Tensor dimensions are **(H, W, D)**. Values inside the tensor\n            correspond to the subclusters, and are grouped by meta-label.\n            `1-19: CSF, 20-29: GM, 30-39: WM, 40-49: Extra-cerebral`.\n    \"\"\"\n    # if no mapping is provided, randomly select the number of subclusters\n    # to use for each meta-label in the format {mlabel: n_subclusters}\n    if mlabel2subclusters is None:\n        mlabel2subclusters = {\n            meta_label: np.random.randint(\n                self.min_subclusters, self.max_subclusters + 1\n            )\n            for meta_label in self.meta_labels\n        }\n    if \"mlabel2subclusters\" in genparams.keys():\n        mlabel2subclusters = genparams[\"mlabel2subclusters\"]\n\n    # load the first seed as the one corresponding to mlabel 1\n    first_mlab = list(mlabel2subclusters.keys())[0]\n    first_subcls = list(seeds[mlabel2subclusters[first_mlab]].keys())[0]\n\n    seed = self.loader(\n        seeds[mlabel2subclusters[first_mlab]][first_subcls],\n        interp=\"nearest\",\n        spatial_size=192,\n        resolution=1.0,\n    )\n    seed = orientation(seed.unsqueeze(0))\n    #\n    # re-orient seeds to RAS\n    for mlabel in self.meta_labels:\n        if mlabel == first_mlab:\n            continue\n        new_seed = self.loader(\n            seeds[mlabel2subclusters[mlabel]][mlabel],\n            interp=\"nearest\",\n            spatial_size=192,\n            resolution=1.0,\n        )\n        new_seed = orientation(new_seed.unsqueeze(0))\n        seed += new_seed\n\n    return seed.long().squeeze(0), {\"mlabel2subclusters\": mlabel2subclusters}\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.intensity.rand_gmm.ImageFromSeeds.sample_intensities","title":"<code>sample_intensities(seeds, device, genparams={})</code>","text":"<p>Sample the intensities from the seeds.</p> <p>Parameters:</p> Name Type Description Default <code>seeds</code> <code>Tensor</code> <p>Tensor with the seeds.</p> required <code>device</code> <code>str</code> <p>Device to use. Should be \"cuda\" or \"cpu\".</p> required <code>genparams</code> <code>dict</code> <p>Dictionary with generation parameters. Defaults to {}. Should contain the keys \"mus\" and \"sigmas\" if the GMM parameters are to be fixed.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Tensor with the intensities.</p> Source code in <code>fetalsyngen/generator/intensity/rand_gmm.py</code> <pre><code>def sample_intensities(\n    self, seeds: torch.Tensor, device: str, genparams: dict = {}\n) -&gt; torch.Tensor:\n    \"\"\"Sample the intensities from the seeds.\n\n    Args:\n        seeds (torch.Tensor): Tensor with the seeds.\n        device (str): Device to use. Should be \"cuda\" or \"cpu\".\n        genparams (dict, optional): Dictionary with generation parameters.\n            Defaults to {}. Should contain the keys \"mus\" and \"sigmas\" if\n            the GMM parameters are to be fixed.\n\n    Returns:\n        torch.Tensor: Tensor with the intensities.\n    \"\"\"\n    nlabels = max(self.seed_labels) + 1\n    nsamp = len(self.seed_labels)\n\n    # # Sample GMMs means and stds\n    mus = (\n        25 + 200 * torch.rand(nlabels, dtype=torch.float, device=device)\n        if \"mus\" not in genparams.keys()\n        else genparams[\"mus\"]\n    )\n    sigmas = (\n        5\n        + 20\n        * torch.rand(\n            nlabels,\n            dtype=torch.float,\n            device=device,\n        )\n        if \"sigmas\" not in genparams.keys()\n        else genparams[\"sigmas\"]\n    )\n\n    # if there are seed labels from the same generation class\n    # set their mean to be the same with some random perturbation\n    if self.generation_classes != self.seed_labels:\n        # Ensure that seeds are within valid range\n        if (seeds &lt; 0).any() or (seeds &gt;= mus.size(0)).any():\n            raise ValueError(\n                f\"Invalid seed indices detected: min={seeds.min().item()}, max={seeds.max().item()} (expected range: 0-{mus.size(0)-1})\"\n            )\n\n        mus[self.seed_labels] = torch.clamp(\n            mus[self.generation_classes]\n            + 25 * torch.randn(nsamp, dtype=torch.float, device=device),\n            0,\n            225,\n        )\n    intensity_image = mus[seeds] + sigmas[seeds] * torch.randn(\n        seeds.shape, dtype=torch.float, device=device\n    )\n    intensity_image[intensity_image &lt; 0] = 0\n\n    return intensity_image, {\n        \"mus\": mus,\n        \"sigmas\": sigmas,\n    }\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.deformation.affine_nonrigid.SpatialDeformation","title":"<code>SpatialDeformation</code>","text":"<p>Class defining the spatial deformation of the image. Combines both random affine and nonlinear transformations to deform the image.</p> Source code in <code>fetalsyngen/generator/deformation/affine_nonrigid.py</code> <pre><code>class SpatialDeformation:\n    \"\"\"\n    Class defining the spatial deformation of the image.\n    Combines both random affine and nonlinear transformations to deform the image.\n    \"\"\"\n\n    def __init__(\n        self,\n        max_rotation: float,\n        max_shear: float,\n        max_scaling: float,\n        size: Iterable[int],\n        prob: float,\n        nonlinear_transform: bool,\n        nonlin_scale_min: float,\n        nonlin_scale_max: float,\n        nonlin_std_max: float,\n        flip_prb: float,\n        device: str,\n    ):\n        \"\"\"Initialize the spatial deformation.\n\n        Args:\n            max_rotation (float): Maximum rotation in degrees.\n            max_shear (float): Maximum shear.\n            max_scaling (float): Maximum scaling.\n            size (Iterable[int]): Size of the output image.\n            prob (float): Probability of applying the deformation.\n            nonlinear_transform (bool): Whether to apply nonlinear transformation.\n            nonlin_scale_min (float): Minimum scale for the nonlinear transformation.\n            nonlin_scale_max (float): Maximum scale for the nonlinear transformation.\n            nonlin_std_max (float): Maximum standard deviation for the nonlinear transformation.\n            flip_prb (float): Probability of flipping the image.\n            device (str): Device to use for computation. Either \"cuda\" or \"cpu\".\n        \"\"\"\n        self.size = size  # 256, 256, 256\n        self.prob = prob\n        self.flip_prb = flip_prb\n\n        # randaffine parameters\n        self.max_rotation = max_rotation\n        self.max_shear = max_shear\n        self.max_scaling = max_scaling\n\n        # nonlinear transform parameters\n        self.nonlinear_transform = nonlinear_transform\n        self.nonlin_scale_min = nonlin_scale_min\n        self.nonlin_scale_max = nonlin_scale_max\n        self.nonlin_std_max = nonlin_std_max\n\n        self.device = device\n\n        self._prepare_grid()\n\n    def _prepare_grid(self):\n\n        xx, yy, zz = np.meshgrid(\n            range(self.size[0]),\n            range(self.size[1]),\n            range(self.size[2]),\n            sparse=False,\n            indexing=\"ij\",\n        )\n        self.xx = torch.tensor(xx, dtype=torch.float, device=self.device)\n        self.yy = torch.tensor(yy, dtype=torch.float, device=self.device)\n        self.zz = torch.tensor(zz, dtype=torch.float, device=self.device)\n        self.c = torch.tensor(\n            (np.array(self.size) - 1) / 2,\n            dtype=torch.float,\n            device=self.device,\n        )\n        self.xc = self.xx - self.c[0]\n        self.yc = self.yy - self.c[1]\n        self.zc = self.zz - self.c[2]\n\n    def deform(\n        self, image, segmentation, output, genparams: dict = {}\n    ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, dict]:\n        \"\"\"Deform the image, segmentation and output.\n\n        Args:\n            image (torch.Tensor): Image to deform.\n            segmentation (torch.Tensor): Segmentation to deform.\n            output (torch.Tensor): Output to deform.\n            genparams (dict, optional): Dictionary with generation parameters. Defaults to {}.\n                Should contain the keys \"affine\" and \"non_rigid\" if the parameters are fixed.\n                Affine parameters should contain the keys \"rotations\", \"shears\" and \"scalings\".\n                Non-rigid parameters should contain the keys \"nonlin_scale\", \"nonlin_std\" and \"size_F_small\".\n\n        Returns:\n            Deformed image, segmentation, output and deformation parameters.\n        \"\"\"\n        deform_params = {}\n        if np.random.rand() &lt; self.prob or len(genparams.keys()) &gt; 0:\n            image_shape = output.shape\n            flip = (\n                np.random.rand() &lt; self.flip_prb\n                if \"flip\" not in genparams.keys()\n                else genparams[\"flip\"]\n            )\n            xx2, yy2, zz2, x1, y1, z1, x2, y2, z2, deform_params = (\n                self.generate_deformation(\n                    image_shape, random_shift=True, genparams=genparams\n                )\n            )\n            # flip the image if nessesary\n            if flip:\n                segmentation = torch.flip(segmentation, [0])\n                output = torch.flip(output, [0])\n                image = torch.flip(image, [0]) if image is not None else None\n\n            output = fast_3D_interp_torch(output, xx2, yy2, zz2, \"linear\")\n            segmentation = fast_3D_interp_torch(\n                segmentation.to(self.device), xx2, yy2, zz2, \"nearest\"\n            )\n            if image is not None:\n                image = fast_3D_interp_torch(\n                    image.to(self.device), xx2, yy2, zz2, \"linear\"\n                )\n\n            deform_params[\"flip\"] = flip\n\n        return image, segmentation, output, deform_params\n\n    def generate_deformation(self, image_shape, random_shift=True, genparams={}):\n\n        # sample affine deformation\n        A, c2, aff_params = self.random_affine_transform(\n            shp=image_shape,\n            max_rotation=self.max_rotation,\n            max_shear=self.max_shear,\n            max_scaling=self.max_scaling,\n            random_shift=random_shift,\n            genparams=genparams.get(\"affine\", {}),\n        )\n\n        # sample nonlinear deformation\n        if self.nonlinear_transform:\n            F, non_rigid_params = self.random_nonlinear_transform(\n                nonlin_scale_min=self.nonlin_scale_min,\n                nonlin_scale_max=self.nonlin_scale_max,\n                nonlin_std_max=self.nonlin_std_max,\n                genparams=genparams.get(\"non_rigid\", {}),\n            )\n        else:\n            F = None\n            non_rigid_params = {}\n\n        # deform the images\n        xx2, yy2, zz2, x1, y1, z1, x2, y2, z2 = self.deform_image(image_shape, A, c2, F)\n\n        return (\n            xx2,\n            yy2,\n            zz2,\n            x1,\n            y1,\n            z1,\n            x2,\n            y2,\n            z2,\n            {\n                \"affine\": aff_params,\n                \"non_rigid\": non_rigid_params,\n            },\n        )\n\n    def random_affine_transform(\n        self,\n        shp,\n        max_rotation,\n        max_shear,\n        max_scaling,\n        random_shift=True,\n        genparams={},\n    ):\n        rotations = (\n            ((2 * max_rotation * np.random.rand(3) - max_rotation) / 180.0 * np.pi)\n            if \"rotations\" not in genparams.keys()\n            else genparams[\"rotations\"]\n        )\n\n        shears = (\n            2 * max_shear * np.random.rand(3) - max_shear\n            if \"shears\" not in genparams.keys()\n            else genparams[\"shears\"]\n        )\n        scalings = (\n            1 + (2 * max_scaling * np.random.rand(3) - max_scaling)\n            if \"scalings\" not in genparams.keys()\n            else genparams[\"scalings\"]\n        )\n        # we divide distance maps by this, not perfect, but better than nothing\n        A = torch.tensor(\n            make_affine_matrix(rotations, shears, scalings),\n            dtype=torch.float,\n            device=self.device,\n        )\n        # sample center\n        if random_shift:\n            max_shift = (\n                torch.tensor(\n                    np.array(shp[0:3]) - self.size,\n                    dtype=torch.float,\n                    device=self.device,\n                )\n            ) / 2\n            max_shift[max_shift &lt; 0] = 0\n            c2 = torch.tensor(\n                (np.array(shp[0:3]) - 1) / 2,\n                dtype=torch.float,\n                device=self.device,\n            ) + (\n                2 * (max_shift * torch.rand(3, dtype=float, device=self.device))\n                - max_shift\n            )\n        else:\n            c2 = torch.tensor(\n                (np.array(shp[0:3]) - 1) / 2,\n                dtype=torch.float,\n                device=self.device,\n            )\n        affine_params = {\n            \"rotations\": rotations,\n            \"shears\": shears,\n            \"scalings\": scalings,\n        }\n\n        return A, c2, affine_params\n\n    def random_nonlinear_transform(\n        self, nonlin_scale_min, nonlin_scale_max, nonlin_std_max, genparams={}\n    ):\n\n        nonlin_scale = (\n            nonlin_scale_min + np.random.rand(1) * (nonlin_scale_max - nonlin_scale_min)\n            if \"nonlin_scale\" not in genparams.keys()\n            else genparams[\"nonlin_scale\"]\n        )\n        size_F_small = (\n            np.round(nonlin_scale * np.array(self.size)).astype(int).tolist()\n            if \"size_F_small\" not in genparams.keys()\n            else genparams[\"size_F_small\"]\n        )\n        nonlin_std = (\n            nonlin_std_max * np.random.rand()\n            if \"nonlin_std\" not in genparams.keys()\n            else genparams[\"nonlin_std\"]\n        )\n        Fsmall = nonlin_std * torch.randn(\n            [*size_F_small, 3], dtype=torch.float, device=self.device\n        )\n        F = myzoom_torch(Fsmall, np.array(self.size) / size_F_small)\n\n        return F, {\n            \"nonlin_scale\": nonlin_scale,\n            \"nonlin_std\": nonlin_std,\n            \"size_F_small\": size_F_small,\n        }\n\n    def deform_image(self, shp, A, c2, F):\n        if F is not None:\n            # deform the images (we do nonlinear \"first\" ie after so we can do heavy coronal deformations in photo mode)\n            xx1 = self.xc + F[:, :, :, 0]\n            yy1 = self.yc + F[:, :, :, 1]\n            zz1 = self.zc + F[:, :, :, 2]\n        else:\n            xx1 = self.xc\n            yy1 = self.yc\n            zz1 = self.zc\n\n        xx2 = A[0, 0] * xx1 + A[0, 1] * yy1 + A[0, 2] * zz1 + c2[0]\n        yy2 = A[1, 0] * xx1 + A[1, 1] * yy1 + A[1, 2] * zz1 + c2[1]\n        zz2 = A[2, 0] * xx1 + A[2, 1] * yy1 + A[2, 2] * zz1 + c2[2]\n        xx2[xx2 &lt; 0] = 0\n        yy2[yy2 &lt; 0] = 0\n        zz2[zz2 &lt; 0] = 0\n        xx2[xx2 &gt; (shp[0] - 1)] = shp[0] - 1\n        yy2[yy2 &gt; (shp[1] - 1)] = shp[1] - 1\n        zz2[zz2 &gt; (shp[2] - 1)] = shp[2] - 1\n\n        # Get the margins for reading images\n        x1 = torch.floor(torch.min(xx2))\n        y1 = torch.floor(torch.min(yy2))\n        z1 = torch.floor(torch.min(zz2))\n        x2 = 1 + torch.ceil(torch.max(xx2))\n        y2 = 1 + torch.ceil(torch.max(yy2))\n        z2 = 1 + torch.ceil(torch.max(zz2))\n        xx2 -= x1\n        yy2 -= y1\n        zz2 -= z1\n\n        x1 = x1.cpu().numpy().astype(int)\n        y1 = y1.cpu().numpy().astype(int)\n        z1 = z1.cpu().numpy().astype(int)\n        x2 = x2.cpu().numpy().astype(int)\n        y2 = y2.cpu().numpy().astype(int)\n        z2 = z2.cpu().numpy().astype(int)\n        return xx2, yy2, zz2, x1, y1, z1, x2, y2, z2\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.deformation.affine_nonrigid.SpatialDeformation.__init__","title":"<code>__init__(max_rotation, max_shear, max_scaling, size, prob, nonlinear_transform, nonlin_scale_min, nonlin_scale_max, nonlin_std_max, flip_prb, device)</code>","text":"<p>Initialize the spatial deformation.</p> <p>Parameters:</p> Name Type Description Default <code>max_rotation</code> <code>float</code> <p>Maximum rotation in degrees.</p> required <code>max_shear</code> <code>float</code> <p>Maximum shear.</p> required <code>max_scaling</code> <code>float</code> <p>Maximum scaling.</p> required <code>size</code> <code>Iterable[int]</code> <p>Size of the output image.</p> required <code>prob</code> <code>float</code> <p>Probability of applying the deformation.</p> required <code>nonlinear_transform</code> <code>bool</code> <p>Whether to apply nonlinear transformation.</p> required <code>nonlin_scale_min</code> <code>float</code> <p>Minimum scale for the nonlinear transformation.</p> required <code>nonlin_scale_max</code> <code>float</code> <p>Maximum scale for the nonlinear transformation.</p> required <code>nonlin_std_max</code> <code>float</code> <p>Maximum standard deviation for the nonlinear transformation.</p> required <code>flip_prb</code> <code>float</code> <p>Probability of flipping the image.</p> required <code>device</code> <code>str</code> <p>Device to use for computation. Either \"cuda\" or \"cpu\".</p> required Source code in <code>fetalsyngen/generator/deformation/affine_nonrigid.py</code> <pre><code>def __init__(\n    self,\n    max_rotation: float,\n    max_shear: float,\n    max_scaling: float,\n    size: Iterable[int],\n    prob: float,\n    nonlinear_transform: bool,\n    nonlin_scale_min: float,\n    nonlin_scale_max: float,\n    nonlin_std_max: float,\n    flip_prb: float,\n    device: str,\n):\n    \"\"\"Initialize the spatial deformation.\n\n    Args:\n        max_rotation (float): Maximum rotation in degrees.\n        max_shear (float): Maximum shear.\n        max_scaling (float): Maximum scaling.\n        size (Iterable[int]): Size of the output image.\n        prob (float): Probability of applying the deformation.\n        nonlinear_transform (bool): Whether to apply nonlinear transformation.\n        nonlin_scale_min (float): Minimum scale for the nonlinear transformation.\n        nonlin_scale_max (float): Maximum scale for the nonlinear transformation.\n        nonlin_std_max (float): Maximum standard deviation for the nonlinear transformation.\n        flip_prb (float): Probability of flipping the image.\n        device (str): Device to use for computation. Either \"cuda\" or \"cpu\".\n    \"\"\"\n    self.size = size  # 256, 256, 256\n    self.prob = prob\n    self.flip_prb = flip_prb\n\n    # randaffine parameters\n    self.max_rotation = max_rotation\n    self.max_shear = max_shear\n    self.max_scaling = max_scaling\n\n    # nonlinear transform parameters\n    self.nonlinear_transform = nonlinear_transform\n    self.nonlin_scale_min = nonlin_scale_min\n    self.nonlin_scale_max = nonlin_scale_max\n    self.nonlin_std_max = nonlin_std_max\n\n    self.device = device\n\n    self._prepare_grid()\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.deformation.affine_nonrigid.SpatialDeformation.deform","title":"<code>deform(image, segmentation, output, genparams={})</code>","text":"<p>Deform the image, segmentation and output.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Tensor</code> <p>Image to deform.</p> required <code>segmentation</code> <code>Tensor</code> <p>Segmentation to deform.</p> required <code>output</code> <code>Tensor</code> <p>Output to deform.</p> required <code>genparams</code> <code>dict</code> <p>Dictionary with generation parameters. Defaults to {}. Should contain the keys \"affine\" and \"non_rigid\" if the parameters are fixed. Affine parameters should contain the keys \"rotations\", \"shears\" and \"scalings\". Non-rigid parameters should contain the keys \"nonlin_scale\", \"nonlin_std\" and \"size_F_small\".</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor, Tensor, dict]</code> <p>Deformed image, segmentation, output and deformation parameters.</p> Source code in <code>fetalsyngen/generator/deformation/affine_nonrigid.py</code> <pre><code>def deform(\n    self, image, segmentation, output, genparams: dict = {}\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, dict]:\n    \"\"\"Deform the image, segmentation and output.\n\n    Args:\n        image (torch.Tensor): Image to deform.\n        segmentation (torch.Tensor): Segmentation to deform.\n        output (torch.Tensor): Output to deform.\n        genparams (dict, optional): Dictionary with generation parameters. Defaults to {}.\n            Should contain the keys \"affine\" and \"non_rigid\" if the parameters are fixed.\n            Affine parameters should contain the keys \"rotations\", \"shears\" and \"scalings\".\n            Non-rigid parameters should contain the keys \"nonlin_scale\", \"nonlin_std\" and \"size_F_small\".\n\n    Returns:\n        Deformed image, segmentation, output and deformation parameters.\n    \"\"\"\n    deform_params = {}\n    if np.random.rand() &lt; self.prob or len(genparams.keys()) &gt; 0:\n        image_shape = output.shape\n        flip = (\n            np.random.rand() &lt; self.flip_prb\n            if \"flip\" not in genparams.keys()\n            else genparams[\"flip\"]\n        )\n        xx2, yy2, zz2, x1, y1, z1, x2, y2, z2, deform_params = (\n            self.generate_deformation(\n                image_shape, random_shift=True, genparams=genparams\n            )\n        )\n        # flip the image if nessesary\n        if flip:\n            segmentation = torch.flip(segmentation, [0])\n            output = torch.flip(output, [0])\n            image = torch.flip(image, [0]) if image is not None else None\n\n        output = fast_3D_interp_torch(output, xx2, yy2, zz2, \"linear\")\n        segmentation = fast_3D_interp_torch(\n            segmentation.to(self.device), xx2, yy2, zz2, \"nearest\"\n        )\n        if image is not None:\n            image = fast_3D_interp_torch(\n                image.to(self.device), xx2, yy2, zz2, \"linear\"\n            )\n\n        deform_params[\"flip\"] = flip\n\n    return image, segmentation, output, deform_params\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandResample","title":"<code>RandResample</code>","text":"<p>               Bases: <code>RandTransform</code></p> <p>Resample the input image to a random resolution sampled uniformly between <code>min_resolution</code> and <code>max_resolution</code> with a probability of <code>prob</code>.</p> <p>If the resolution is smaller than the input resolution, no resampling is performed.</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>class RandResample(RandTransform):\n    \"\"\"Resample the input image to a random resolution sampled uniformly between\n    `min_resolution` and `max_resolution` with a probability of `prob`.\n\n    If the resolution is smaller than the input resolution, no resampling is performed.\n    \"\"\"\n\n    def __init__(\n        self,\n        prob: float,\n        min_resolution: float,\n        max_resolution: float,\n    ):\n        \"\"\"\n        Initialize the augmentation parameters.\n\n        Args:\n            prob (float): Probability of applying the augmentation.\n            min_resolution (float): Minimum resolution for the augmentation (in mm).\n            max_resolution (float): Maximum resolution for the augmentation.\n        \"\"\"\n        self.prob = prob\n        self.min_resolution = min_resolution\n        self.max_resolution = max_resolution\n\n    def __call__(\n        self, output, input_resolution, device, genparams: dict = {}\n    ) -&gt; torch.Tensor:\n        \"\"\"Apply the resampling to the input image.\n\n        Args:\n            output (torch.Tensor): Input image to resample.\n            input_resolution (np.array): Resolution of the input image.\n            device (str): Device to use for computation.\n            genparams (dict): Generation parameters.\n                Default: {}. Should contain the key \"spacing\" if the spacing is fixed.\n\n        Returns:\n            Resampled image.\n        \"\"\"\n        if np.random.rand() &lt; self.prob or \"spacing\" in genparams.keys():\n            input_size = np.array(output.shape)\n            spacing = (\n                np.array([1.0, 1.0, 1.0])\n                * self.random_uniform(self.min_resolution, self.max_resolution)\n                if \"spacing\" not in genparams.keys()\n                else genparams[\"spacing\"]\n            )\n            # Ensure spacing and input_resolution are numpy arrays\n            spacing = np.array(spacing)\n            input_resolution = np.array(input_resolution)\n\n            # calculate stds of gaussian kernels\n            # used for blurring to simulate resampling\n            # the data to different resolutions\n            stds = (\n                (0.85 + 0.3 * np.random.rand())\n                * np.log(5)\n                / np.pi\n                * spacing\n                / input_resolution\n            )\n            # no blur if thickness is equal or smaller to the resolution of the training data\n            stds[spacing &lt;= input_resolution] = 0.0\n            output_blurred = gaussian_blur_3d(output, stds, device)\n\n            # resize the blurred output to the new resolution\n            new_size = (np.array(input_size) * input_resolution / spacing).astype(int)\n\n            # calculate the factors for the interpolation\n            factors = np.array(new_size) / np.array(input_size)\n            # delta is the offset for the interpolation\n            delta = (1.0 - factors) / (2.0 * factors)\n            vx = np.arange(\n                delta[0], delta[0] + new_size[0] / factors[0], 1 / factors[0]\n            )[: new_size[0]]\n            vy = np.arange(\n                delta[1], delta[1] + new_size[1] / factors[1], 1 / factors[1]\n            )[: new_size[1]]\n            vz = np.arange(\n                delta[2], delta[2] + new_size[2] / factors[2], 1 / factors[2]\n            )[: new_size[2]]\n            II, JJ, KK = np.meshgrid(vx, vy, vz, sparse=False, indexing=\"ij\")\n            II = torch.tensor(II, dtype=torch.float, device=device)\n            JJ = torch.tensor(JJ, dtype=torch.float, device=device)\n            KK = torch.tensor(KK, dtype=torch.float, device=device)\n\n            output_resized = fast_3D_interp_torch(output_blurred, II, JJ, KK, \"linear\")\n            return output_resized, factors, {\"spacing\": spacing.tolist()}\n        else:\n            return output, None, {\"spacing\": None}\n\n    def resize_back(self, output_resized, factors):\n        if factors is not None:\n            output_resized = myzoom_torch(output_resized, 1 / factors)\n            return output_resized / torch.max(output_resized)\n        else:\n            return output_resized\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandResample.__init__","title":"<code>__init__(prob, min_resolution, max_resolution)</code>","text":"<p>Initialize the augmentation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>prob</code> <code>float</code> <p>Probability of applying the augmentation.</p> required <code>min_resolution</code> <code>float</code> <p>Minimum resolution for the augmentation (in mm).</p> required <code>max_resolution</code> <code>float</code> <p>Maximum resolution for the augmentation.</p> required Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>def __init__(\n    self,\n    prob: float,\n    min_resolution: float,\n    max_resolution: float,\n):\n    \"\"\"\n    Initialize the augmentation parameters.\n\n    Args:\n        prob (float): Probability of applying the augmentation.\n        min_resolution (float): Minimum resolution for the augmentation (in mm).\n        max_resolution (float): Maximum resolution for the augmentation.\n    \"\"\"\n    self.prob = prob\n    self.min_resolution = min_resolution\n    self.max_resolution = max_resolution\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandResample.__call__","title":"<code>__call__(output, input_resolution, device, genparams={})</code>","text":"<p>Apply the resampling to the input image.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Tensor</code> <p>Input image to resample.</p> required <code>input_resolution</code> <code>array</code> <p>Resolution of the input image.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>genparams</code> <code>dict</code> <p>Generation parameters. Default: {}. Should contain the key \"spacing\" if the spacing is fixed.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Resampled image.</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>def __call__(\n    self, output, input_resolution, device, genparams: dict = {}\n) -&gt; torch.Tensor:\n    \"\"\"Apply the resampling to the input image.\n\n    Args:\n        output (torch.Tensor): Input image to resample.\n        input_resolution (np.array): Resolution of the input image.\n        device (str): Device to use for computation.\n        genparams (dict): Generation parameters.\n            Default: {}. Should contain the key \"spacing\" if the spacing is fixed.\n\n    Returns:\n        Resampled image.\n    \"\"\"\n    if np.random.rand() &lt; self.prob or \"spacing\" in genparams.keys():\n        input_size = np.array(output.shape)\n        spacing = (\n            np.array([1.0, 1.0, 1.0])\n            * self.random_uniform(self.min_resolution, self.max_resolution)\n            if \"spacing\" not in genparams.keys()\n            else genparams[\"spacing\"]\n        )\n        # Ensure spacing and input_resolution are numpy arrays\n        spacing = np.array(spacing)\n        input_resolution = np.array(input_resolution)\n\n        # calculate stds of gaussian kernels\n        # used for blurring to simulate resampling\n        # the data to different resolutions\n        stds = (\n            (0.85 + 0.3 * np.random.rand())\n            * np.log(5)\n            / np.pi\n            * spacing\n            / input_resolution\n        )\n        # no blur if thickness is equal or smaller to the resolution of the training data\n        stds[spacing &lt;= input_resolution] = 0.0\n        output_blurred = gaussian_blur_3d(output, stds, device)\n\n        # resize the blurred output to the new resolution\n        new_size = (np.array(input_size) * input_resolution / spacing).astype(int)\n\n        # calculate the factors for the interpolation\n        factors = np.array(new_size) / np.array(input_size)\n        # delta is the offset for the interpolation\n        delta = (1.0 - factors) / (2.0 * factors)\n        vx = np.arange(\n            delta[0], delta[0] + new_size[0] / factors[0], 1 / factors[0]\n        )[: new_size[0]]\n        vy = np.arange(\n            delta[1], delta[1] + new_size[1] / factors[1], 1 / factors[1]\n        )[: new_size[1]]\n        vz = np.arange(\n            delta[2], delta[2] + new_size[2] / factors[2], 1 / factors[2]\n        )[: new_size[2]]\n        II, JJ, KK = np.meshgrid(vx, vy, vz, sparse=False, indexing=\"ij\")\n        II = torch.tensor(II, dtype=torch.float, device=device)\n        JJ = torch.tensor(JJ, dtype=torch.float, device=device)\n        KK = torch.tensor(KK, dtype=torch.float, device=device)\n\n        output_resized = fast_3D_interp_torch(output_blurred, II, JJ, KK, \"linear\")\n        return output_resized, factors, {\"spacing\": spacing.tolist()}\n    else:\n        return output, None, {\"spacing\": None}\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandBiasField","title":"<code>RandBiasField</code>","text":"<p>               Bases: <code>RandTransform</code></p> <p>Add a random bias field to the input image with a probability of <code>prob</code>.</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>class RandBiasField(RandTransform):\n    \"\"\"Add a random bias field to the input image with a probability of `prob`.\"\"\"\n\n    def __init__(\n        self,\n        prob: float,\n        scale_min: float,\n        scale_max: float,\n        std_min: float,\n        std_max: float,\n    ):\n        \"\"\"\n\n        Args:\n            prob: Probability of applying the augmentation.\n            scale_min: Minimum scale of the bias field.\n            scale_max: Maximum scale of the bias field.\n            std_min: Minimum standard deviation of the bias field.\n            std_max: Maximum standard deviation of the bias.\n        \"\"\"\n\n        self.prob = prob\n        self.scale_min = scale_min\n        self.scale_max = scale_max\n        self.std_min = std_min\n        self.std_max = std_max\n\n    def __call__(self, output, device, genparams: dict = {}) -&gt; torch.Tensor:\n        \"\"\"Apply the bias field to the input image.\n\n        Args:\n            output (torch.Tensor): Input image to apply the bias field.\n            device (str): Device to use for computation.\n            genparams (dict): Generation parameters.\n                Default: {}. Should contain the keys \"bf_scale\", \"bf_std\" and \"bf_size\" if\n                the bias field parameters are fixed.\n\n        Returns:\n            Image with the bias field applied.\n        \"\"\"\n        if np.random.rand() &lt; self.prob or len(genparams.keys()) &gt; 0:\n            image_size = output.shape\n            bf_scale = (\n                self.scale_min + np.random.rand(1) * (self.scale_max - self.scale_min)\n                if \"bf_scale\" not in genparams.keys()\n                else genparams[\"bf_scale\"]\n            )\n            bf_size = np.round(bf_scale * np.array(image_size)).astype(int).tolist()\n            bf_std = (\n                self.std_min + (self.std_max - self.std_min) * np.random.rand(1)\n                if \"bf_std\" not in genparams.keys()\n                else genparams[\"bf_std\"]\n            )\n\n            bf_low_scale = torch.tensor(\n                bf_std,\n                dtype=torch.float,\n                device=device,\n            ) * torch.randn(bf_size, dtype=torch.float, device=device)\n            bf_interp = myzoom_torch(bf_low_scale, np.array(image_size) / bf_size)\n            bf = torch.exp(bf_interp)\n\n            return output * bf, {\n                \"bf_scale\": bf_scale,\n                \"bf_std\": bf_std,\n                \"bf_size\": bf_size,\n            }\n        else:\n            return output, {\"bf_scale\": None, \"bf_std\": None, \"bf_size\": None}\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandBiasField.__init__","title":"<code>__init__(prob, scale_min, scale_max, std_min, std_max)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>prob</code> <code>float</code> <p>Probability of applying the augmentation.</p> required <code>scale_min</code> <code>float</code> <p>Minimum scale of the bias field.</p> required <code>scale_max</code> <code>float</code> <p>Maximum scale of the bias field.</p> required <code>std_min</code> <code>float</code> <p>Minimum standard deviation of the bias field.</p> required <code>std_max</code> <code>float</code> <p>Maximum standard deviation of the bias.</p> required Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>def __init__(\n    self,\n    prob: float,\n    scale_min: float,\n    scale_max: float,\n    std_min: float,\n    std_max: float,\n):\n    \"\"\"\n\n    Args:\n        prob: Probability of applying the augmentation.\n        scale_min: Minimum scale of the bias field.\n        scale_max: Maximum scale of the bias field.\n        std_min: Minimum standard deviation of the bias field.\n        std_max: Maximum standard deviation of the bias.\n    \"\"\"\n\n    self.prob = prob\n    self.scale_min = scale_min\n    self.scale_max = scale_max\n    self.std_min = std_min\n    self.std_max = std_max\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandBiasField.__call__","title":"<code>__call__(output, device, genparams={})</code>","text":"<p>Apply the bias field to the input image.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Tensor</code> <p>Input image to apply the bias field.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>genparams</code> <code>dict</code> <p>Generation parameters. Default: {}. Should contain the keys \"bf_scale\", \"bf_std\" and \"bf_size\" if the bias field parameters are fixed.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Image with the bias field applied.</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>def __call__(self, output, device, genparams: dict = {}) -&gt; torch.Tensor:\n    \"\"\"Apply the bias field to the input image.\n\n    Args:\n        output (torch.Tensor): Input image to apply the bias field.\n        device (str): Device to use for computation.\n        genparams (dict): Generation parameters.\n            Default: {}. Should contain the keys \"bf_scale\", \"bf_std\" and \"bf_size\" if\n            the bias field parameters are fixed.\n\n    Returns:\n        Image with the bias field applied.\n    \"\"\"\n    if np.random.rand() &lt; self.prob or len(genparams.keys()) &gt; 0:\n        image_size = output.shape\n        bf_scale = (\n            self.scale_min + np.random.rand(1) * (self.scale_max - self.scale_min)\n            if \"bf_scale\" not in genparams.keys()\n            else genparams[\"bf_scale\"]\n        )\n        bf_size = np.round(bf_scale * np.array(image_size)).astype(int).tolist()\n        bf_std = (\n            self.std_min + (self.std_max - self.std_min) * np.random.rand(1)\n            if \"bf_std\" not in genparams.keys()\n            else genparams[\"bf_std\"]\n        )\n\n        bf_low_scale = torch.tensor(\n            bf_std,\n            dtype=torch.float,\n            device=device,\n        ) * torch.randn(bf_size, dtype=torch.float, device=device)\n        bf_interp = myzoom_torch(bf_low_scale, np.array(image_size) / bf_size)\n        bf = torch.exp(bf_interp)\n\n        return output * bf, {\n            \"bf_scale\": bf_scale,\n            \"bf_std\": bf_std,\n            \"bf_size\": bf_size,\n        }\n    else:\n        return output, {\"bf_scale\": None, \"bf_std\": None, \"bf_size\": None}\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandNoise","title":"<code>RandNoise</code>","text":"<p>               Bases: <code>RandTransform</code></p> <p>Add random Gaussian noise to the input image with a probability of <code>prob</code>.</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>class RandNoise(RandTransform):\n    \"\"\"Add random Gaussian noise to the input image with a probability of `prob`.\"\"\"\n\n    def __init__(self, prob: float, std_min: float, std_max: float):\n        \"\"\"\n        The image scale is 0-255 so the noise is added in the same scale.\n        Args:\n            prob: Probability of applying the augmentation.\n            std_min: Minimum standard deviation of the noise.\n            std_max: Maximum standard deviation of the noise\n        \"\"\"\n        self.prob = prob\n        self.std_min = std_min\n        self.std_max = std_max\n\n    def __call__(self, output, device, genparams: dict = {}) -&gt; torch.Tensor:\n        \"\"\"Apply the noise to the input image.\n\n        Args:\n            output (torch.Tensor): Input image to apply the noise.\n            device (str): Device to use for computation.\n            genparams (dict): Generation parameters.\n                Default: {}. Should contain the key \"noise_std\" if the noise standard deviation is fixed.\n\n        Returns:\n            Image with the noise applied.\"\"\"\n        noise_std = None\n        if np.random.rand() &lt; self.prob or \"noise_std\" in genparams.keys():\n            noise_std = (\n                self.std_min + (self.std_max - self.std_min) * np.random.rand(1)\n                if \"noise_std\" not in genparams.keys()\n                else genparams[\"noise_std\"]\n            )\n\n            noise_std = torch.tensor(\n                noise_std,\n                dtype=torch.float,\n                device=device,\n            )\n            output = output + noise_std * torch.randn(\n                output.shape, dtype=torch.float, device=device\n            )\n            output[output &lt; 0] = 0\n        noise_std = noise_std.item() if noise_std is not None else None\n        return output, {\"noise_std\": noise_std}\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandNoise.__init__","title":"<code>__init__(prob, std_min, std_max)</code>","text":"<p>The image scale is 0-255 so the noise is added in the same scale. Args:     prob: Probability of applying the augmentation.     std_min: Minimum standard deviation of the noise.     std_max: Maximum standard deviation of the noise</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>def __init__(self, prob: float, std_min: float, std_max: float):\n    \"\"\"\n    The image scale is 0-255 so the noise is added in the same scale.\n    Args:\n        prob: Probability of applying the augmentation.\n        std_min: Minimum standard deviation of the noise.\n        std_max: Maximum standard deviation of the noise\n    \"\"\"\n    self.prob = prob\n    self.std_min = std_min\n    self.std_max = std_max\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandNoise.__call__","title":"<code>__call__(output, device, genparams={})</code>","text":"<p>Apply the noise to the input image.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Tensor</code> <p>Input image to apply the noise.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>genparams</code> <code>dict</code> <p>Generation parameters. Default: {}. Should contain the key \"noise_std\" if the noise standard deviation is fixed.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Image with the noise applied.</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>def __call__(self, output, device, genparams: dict = {}) -&gt; torch.Tensor:\n    \"\"\"Apply the noise to the input image.\n\n    Args:\n        output (torch.Tensor): Input image to apply the noise.\n        device (str): Device to use for computation.\n        genparams (dict): Generation parameters.\n            Default: {}. Should contain the key \"noise_std\" if the noise standard deviation is fixed.\n\n    Returns:\n        Image with the noise applied.\"\"\"\n    noise_std = None\n    if np.random.rand() &lt; self.prob or \"noise_std\" in genparams.keys():\n        noise_std = (\n            self.std_min + (self.std_max - self.std_min) * np.random.rand(1)\n            if \"noise_std\" not in genparams.keys()\n            else genparams[\"noise_std\"]\n        )\n\n        noise_std = torch.tensor(\n            noise_std,\n            dtype=torch.float,\n            device=device,\n        )\n        output = output + noise_std * torch.randn(\n            output.shape, dtype=torch.float, device=device\n        )\n        output[output &lt; 0] = 0\n    noise_std = noise_std.item() if noise_std is not None else None\n    return output, {\"noise_std\": noise_std}\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandGamma","title":"<code>RandGamma</code>","text":"<p>               Bases: <code>RandTransform</code></p> <p>Apply gamma correction to the input image with a probability of <code>prob</code>.</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>class RandGamma(RandTransform):\n    \"\"\"Apply gamma correction to the input image with a probability of `prob`.\"\"\"\n\n    def __init__(self, prob: float, gamma_std: float):\n        \"\"\"\n        Args:\n            prob: Probability of applying the augmentation.\n            gamma_std: Standard deviation of the gamma correction.\n        \"\"\"\n        self.prob = prob\n        self.gamma_std = gamma_std\n\n    def __call__(self, output, device, genparams: dict = {}) -&gt; torch.Tensor:\n        \"\"\"Apply the gamma correction to the input image.\n\n        Args:\n            output (torch.Tensor): Input image to apply the gamma correction.\n            device (str): Device to use for computation.\n            genparams (dict): Generation parameters.\n                Default: {}. Should contain the key \"gamma\" if the gamma correction is fixed.\n\n        Returns:\n            Image with the gamma correction applied.\n        \"\"\"\n        gamma = None\n        if np.random.rand() &lt; self.prob or \"gamma\" in genparams.keys():\n            gamma = (\n                np.exp(self.gamma_std * np.random.randn(1)[0])\n                if \"gamma\" not in genparams.keys()\n                else genparams[\"gamma\"]\n            )\n            gamma_tensor = torch.tensor(\n                gamma,\n                dtype=float,\n                device=device,\n            )\n            output = 300.0 * (output / 300.0) ** gamma_tensor\n        return output, {\"gamma\": gamma}\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandGamma.__init__","title":"<code>__init__(prob, gamma_std)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>prob</code> <code>float</code> <p>Probability of applying the augmentation.</p> required <code>gamma_std</code> <code>float</code> <p>Standard deviation of the gamma correction.</p> required Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>def __init__(self, prob: float, gamma_std: float):\n    \"\"\"\n    Args:\n        prob: Probability of applying the augmentation.\n        gamma_std: Standard deviation of the gamma correction.\n    \"\"\"\n    self.prob = prob\n    self.gamma_std = gamma_std\n</code></pre>"},{"location":"generation/#fetalsyngen.generator.augmentation.synthseg.RandGamma.__call__","title":"<code>__call__(output, device, genparams={})</code>","text":"<p>Apply the gamma correction to the input image.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Tensor</code> <p>Input image to apply the gamma correction.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>genparams</code> <code>dict</code> <p>Generation parameters. Default: {}. Should contain the key \"gamma\" if the gamma correction is fixed.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Image with the gamma correction applied.</p> Source code in <code>fetalsyngen/generator/augmentation/synthseg.py</code> <pre><code>def __call__(self, output, device, genparams: dict = {}) -&gt; torch.Tensor:\n    \"\"\"Apply the gamma correction to the input image.\n\n    Args:\n        output (torch.Tensor): Input image to apply the gamma correction.\n        device (str): Device to use for computation.\n        genparams (dict): Generation parameters.\n            Default: {}. Should contain the key \"gamma\" if the gamma correction is fixed.\n\n    Returns:\n        Image with the gamma correction applied.\n    \"\"\"\n    gamma = None\n    if np.random.rand() &lt; self.prob or \"gamma\" in genparams.keys():\n        gamma = (\n            np.exp(self.gamma_std * np.random.randn(1)[0])\n            if \"gamma\" not in genparams.keys()\n            else genparams[\"gamma\"]\n        )\n        gamma_tensor = torch.tensor(\n            gamma,\n            dtype=float,\n            device=device,\n        )\n        output = 300.0 * (output / 300.0) ** gamma_tensor\n    return output, {\"gamma\": gamma}\n</code></pre>"},{"location":"generation/#fixed-image-generation","title":"Fixed Image Generation","text":""},{"location":"seed_generation/","title":"Seed Generation","text":""},{"location":"seed_generation/#introduction","title":"Introduction","text":"<p>Seed generation is the first step in creating synthetic fetal brain MRI images with FetalSynthGen. We perform is separately from the generation step, as data pre-processing as this process is time consuming and can be done once for all images.</p> <ul> <li>It addresses the limited number of segmentation classes in fetal brain MRI.</li> <li>It allows the simulation of finer variations in tissue data.</li> <li>It reduces reliance on artificial contrast between segmentation labels and instead focuses on simulating anatomical variability within tissue types, helping to prevent models from learning label-specific contrast boundaries that may not exist in real images, which can be a problem with super-resolution MRI.</li> </ul> <p>How is it performed?</p> <ul> <li>First, original segmentation labels are merged into four meta-labels: cerebrospinal fluid (CSF), white matter (WM), gray matter (GM), and non-brain tissue (skull and surrounding tissue).</li> <li>Then, the Expectation-Maximisation (EM) algorithm is used for intensity clustering within each meta-label.</li> <li>This process divides each meta-label into a random number of subclasses, from one to four. These subclasses become the basis for generating synthetic images.</li> <li>Later in the generation pipeline, a Gaussian Mixture Model (GMM) is sampled for each subclass, and is used to sample intensities for voxels inside of it.</li> </ul> <p>This process ensures the synthetic images better reflect the heterogeneous nature of fetal brain tissue and the variability seen in real MRI data. See figure below for an example of seed generation.</p> <p> </p>"},{"location":"seed_generation/#usage","title":"Usage","text":"<p>The script <code>fetalsyngen/scripts/generate_seeds.py</code> is used to generate seeds for the FetalSynthGen pipeline.</p> <p><code>generate_seeds.py [-h] --bids_path BIDS_PATH --out_path OUT_PATH [--max_subclasses MAX_SUBCLASSES] --annotation {feta,dhcp}</code></p> <pre><code>options:\n  -h, --help            show this help message and exit\n  --bids_path BIDS_PATH\n                        Path to BIDS folder with the segmentations and images for seeds generation\n  --out_path OUT_PATH   Path to save the seeds\n  --max_subclasses MAX_SUBCLASSES\n                        How many subclasses to simulate for each tissue type (meta-label)\n  --annotation {feta,dhcp}\n                        Annotation type. Should be either 'feta' or 'dhcp'\n\nExample: python generate_seeds.py --bids_path /path/to/bids --out_path /path/to/out --max_subclasses 10 --annotation feta\n</code></pre> <p>Note</p> <ul> <li>The <code>--annotation</code> flag specifies the type of segmentation labels to use. The <code>feta</code> option uses the FeTA Challenge labels, while the <code>dhcp</code> option uses the <code>Developing Human Connectome Project (dHCP)</code> labels as they have different segmentation classes.</li> </ul>"},{"location":"seed_generation/#output-format","title":"Output Format","text":"<p>The output seeds are saved as <code>int8</code> NIfTI files, with the same dimensions as the input images to speed up the seed loading process during generation.</p> <p>The output folder structure is as follows:</p> <pre><code>\u251c\u2500\u2500 derivatives\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 seeds\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 subclasses_{1-max_subclasses}\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 sub-sta30\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0  \u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 anat\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0  \u00a0\u00a0  \u00a0\u00a0     \u2514\u2500\u2500 sub-sta30_rec-irtk_T2w_dseg_mlabel_{1-4}.nii.gz\n\u2514\u2500\u2500 sub-sta30\n\u00a0\u00a0 \u2514\u2500\u2500 anat\n\u00a0\u00a0     \u251c\u2500\u2500 sub-sta30_rec-irtk_T2w_dseg.nii.gz\n\u00a0\u00a0     \u2514\u2500\u2500 sub-sta30_rec-irtk_T2w.nii.gz\n</code></pre> <p>If you wish to run the seed generation for your own annotation labels, please update the script yourself to include a custom annotation scheme and meta-labels support.</p> <p>Warning</p> <p>\ud83d\udcdd Resampling: For the correct work of the generator, all input data needs to be resampled to the same spatial size and resolution. Please perform this step before seed generation, as seeds need to match the images/segmentations.</p> <p>Contact us if you need help with this.</p>"},{"location":"sr_artif_api/","title":"Super-resolution artifacts","text":"<p>Super-resolution reconstruction algorithms are used commonly in fetal MRI imaging to improve the resolution of the images, due to specifics of fetal (brain) MRI acquisitions (see figure below [1]).  </p> <p>Fig. 1. (A) Illustration of the data acquisition and reconstruction in fetal brain MRI. Stacks of 2D images are acquired at multiple orientations and combined into a single 3D volume using super-resolution reconstruction techniques. Quality control checks are implemented on the stacks of 2D images (Step 1) and on the SRR volume (Step 2). (B) SRR volumes with different quality scores. (C) Example of the different SR artifacts</p> <p>We implemented a SR artifact simulation framework to generate synthetic fetal brain MRI images with different types of artifacts. To enable it, simply pass corresponding classes described below to the generator class.</p> <p>You can see examples of its application in the following notebook. It consists of following classes that each implement a specific type(s) of artifacts:</p>"},{"location":"sr_artif_api/#cortex-blur","title":"Cortex blur","text":"<p>Default configuration: <pre><code>blur_cortex:\n  _target_: fetalsyngen.generator.augmentation.artifacts.BlurCortex\n  prob: 0.4\n  cortex_label: 2\n  nblur_min: 50\n  nblur_max: 200\n  sigma_gamma_loc: 3\n  sigma_gamma_scale: 1\n  std_blur_shape: 2\n  std_blur_scale: 1\n</code></pre></p>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.BlurCortex","title":"<code>fetalsyngen.generator.augmentation.artifacts.BlurCortex</code>","text":"<p>               Bases: <code>RandTransform</code></p> <p>Blurs the cortex in the image (like in cases with imprecise reconstructions). Given a <code>cortex_label</code>,  blurs the cortex with a Gaussian blur (shape and scale defined by <code>std_blur_shape</code> and <code>std_blur_scale</code>). Then, generates 3D Gaussian blobs (between <code>nblur_min</code> and <code>nblur_max</code>) with a given width (parametrized by a gamma distribution with parameters <code>sigma_gamma_loc</code> and <code>sigma_gamma_scale</code>) defining where the blurring will be applied.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>class BlurCortex(RandTransform):\n    \"\"\"Blurs the cortex in the image (like in cases with imprecise reconstructions).\n    Given a `cortex_label`,  blurs the cortex with a Gaussian blur (shape and scale defined\n    by `std_blur_shape` and `std_blur_scale`). Then, generates 3D Gaussian blobs (between `nblur_min` and `nblur_max`)\n    with a given width (parametrized by a gamma distribution with parameters `sigma_gamma_loc` and `sigma_gamma_scale`) defining where the blurring will be applied.\n    \"\"\"\n\n    def __init__(\n        self,\n        prob: float,\n        cortex_label: int,\n        nblur_min: int,\n        nblur_max: int,\n        sigma_gamma_loc: int = 3,\n        sigma_gamma_scale: int = 1,\n        std_blur_shape: int = 2,\n        std_blur_scale: int = 1,\n    ):\n        \"\"\"\n        Initialize the augmentation parameters.\n\n        Args:\n            prob (float): Probability of applying the augmentation.\n            cortex_label (int): Label of the cortex in the segmentation.\n            nblur_min (int): Minimum number of blurs to apply.\n            nblur_max (int): Maximum number of blurs to apply.\n            sigma_gamma_loc (int): Location parameter of the gamma distribution for the blurring width.\n            sigma_gamma_scale (int): Scale parameter of the gamma distribution for the blurring width.\n            std_blur_shape (int): Shape parameter of the gamma distribution defining the Gaussian blur standard deviation.\n            std_blur_scale (int): Scale parameter of the gamma distribution defining the Gaussian blur blur standard deviation.\n        \"\"\"\n        self.prob = prob\n        self.cortex_label = cortex_label\n        self.nblur_min = nblur_min\n        self.nblur_max = nblur_max\n        self.sigma_gamma_loc = sigma_gamma_loc\n        self.sigma_gamma_scale = sigma_gamma_scale\n        self.std_blur_shape = std_blur_shape\n        self.std_blur_scale = std_blur_scale\n\n    def blur_proba(self, shape, cortex, device):\n        \"\"\"\n        Generate the probability map for the blurring based on the cortex segmentation.\n        This functions puts more probability of a blurring occuring in the frontal region\n        of the brain, as observed empirically.\n        \"\"\"\n        x, y, z = shape\n        # Blurring is more likely to happen in the frontal lobe\n        cortex_prob = mog_3d_tensor(\n            shape,\n            [(0, y, z // 2), (x, y, z // 2)],\n            [x // 5, y // 5],\n            device,\n        )\n        idx_cortex = torch.where(cortex &gt; 0)\n        cortex_prob = cortex_prob[idx_cortex]\n        cortex_prob = cortex_prob / cortex_prob.sum()\n        return cortex_prob\n\n    def __call__(\n        self, output, seg, device, genparams: dict = {}, **kwargs\n    ) -&gt; tuple[torch.Tensor, dict]:\n        \"\"\"Apply the blurring to the input image.\n\n        Args:\n            output (torch.Tensor): Input image to resample.\n            seg (torch.Tensor): Input segmentation corresponding to the image.\n            device (str): Device to use for computation.\n            genparams (dict): Generation parameters.\n                Default: {}. Should contain the key \"spacing\" if the spacing is fixed.\n\n        Returns:\n            Resampled image  and Metadata containing the blurring parameters.\n        \"\"\"\n        if np.random.rand() &lt; self.prob or len(genparams.keys()) &gt; 0:\n            nblur = (\n                np.random.randint(self.nblur_min, self.nblur_max)\n                if \"nblur\" not in genparams.keys()\n                else genparams[\"nblur\"]\n            )\n            std_blurs = np.random.gamma(self.std_blur_shape, self.std_blur_scale, 3)\n\n            cortex = seg == self.cortex_label\n            cortex_prob = self.blur_proba(output.shape, cortex, device)\n            # Reshape cortex prob onto to the cortex\n\n            idx = torch.multinomial(cortex_prob, nblur)\n\n            idx_cortex = torch.where(cortex &gt; 0)\n            centers = [\n                [idx_cortex[i][id.item()].item() for i in range(3)] for id in idx\n            ]\n            # Spatial merging parameters.\n            sigmas = np.random.gamma(\n                self.sigma_gamma_loc, self.sigma_gamma_scale, (nblur, 3)\n            )\n            gaussian = mog_3d_tensor(\n                output.shape,\n                centers=centers,\n                sigmas=sigmas,\n                device=output.device,\n            )\n\n            # Generate the blurred image\n            output_blur = gaussian_blur_3d(\n                output.float(), stds=std_blurs, device=output.device\n            )\n            output = output * (1 - gaussian) + output_blur * gaussian\n            return output, {\n                \"nblur\": nblur,\n            }\n\n        else:\n            return output, {\n                \"nblur\": None,\n            }\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.BlurCortex.__init__","title":"<code>__init__(prob, cortex_label, nblur_min, nblur_max, sigma_gamma_loc=3, sigma_gamma_scale=1, std_blur_shape=2, std_blur_scale=1)</code>","text":"<p>Initialize the augmentation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>prob</code> <code>float</code> <p>Probability of applying the augmentation.</p> required <code>cortex_label</code> <code>int</code> <p>Label of the cortex in the segmentation.</p> required <code>nblur_min</code> <code>int</code> <p>Minimum number of blurs to apply.</p> required <code>nblur_max</code> <code>int</code> <p>Maximum number of blurs to apply.</p> required <code>sigma_gamma_loc</code> <code>int</code> <p>Location parameter of the gamma distribution for the blurring width.</p> <code>3</code> <code>sigma_gamma_scale</code> <code>int</code> <p>Scale parameter of the gamma distribution for the blurring width.</p> <code>1</code> <code>std_blur_shape</code> <code>int</code> <p>Shape parameter of the gamma distribution defining the Gaussian blur standard deviation.</p> <code>2</code> <code>std_blur_scale</code> <code>int</code> <p>Scale parameter of the gamma distribution defining the Gaussian blur blur standard deviation.</p> <code>1</code> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def __init__(\n    self,\n    prob: float,\n    cortex_label: int,\n    nblur_min: int,\n    nblur_max: int,\n    sigma_gamma_loc: int = 3,\n    sigma_gamma_scale: int = 1,\n    std_blur_shape: int = 2,\n    std_blur_scale: int = 1,\n):\n    \"\"\"\n    Initialize the augmentation parameters.\n\n    Args:\n        prob (float): Probability of applying the augmentation.\n        cortex_label (int): Label of the cortex in the segmentation.\n        nblur_min (int): Minimum number of blurs to apply.\n        nblur_max (int): Maximum number of blurs to apply.\n        sigma_gamma_loc (int): Location parameter of the gamma distribution for the blurring width.\n        sigma_gamma_scale (int): Scale parameter of the gamma distribution for the blurring width.\n        std_blur_shape (int): Shape parameter of the gamma distribution defining the Gaussian blur standard deviation.\n        std_blur_scale (int): Scale parameter of the gamma distribution defining the Gaussian blur blur standard deviation.\n    \"\"\"\n    self.prob = prob\n    self.cortex_label = cortex_label\n    self.nblur_min = nblur_min\n    self.nblur_max = nblur_max\n    self.sigma_gamma_loc = sigma_gamma_loc\n    self.sigma_gamma_scale = sigma_gamma_scale\n    self.std_blur_shape = std_blur_shape\n    self.std_blur_scale = std_blur_scale\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.BlurCortex.blur_proba","title":"<code>blur_proba(shape, cortex, device)</code>","text":"<p>Generate the probability map for the blurring based on the cortex segmentation. This functions puts more probability of a blurring occuring in the frontal region of the brain, as observed empirically.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def blur_proba(self, shape, cortex, device):\n    \"\"\"\n    Generate the probability map for the blurring based on the cortex segmentation.\n    This functions puts more probability of a blurring occuring in the frontal region\n    of the brain, as observed empirically.\n    \"\"\"\n    x, y, z = shape\n    # Blurring is more likely to happen in the frontal lobe\n    cortex_prob = mog_3d_tensor(\n        shape,\n        [(0, y, z // 2), (x, y, z // 2)],\n        [x // 5, y // 5],\n        device,\n    )\n    idx_cortex = torch.where(cortex &gt; 0)\n    cortex_prob = cortex_prob[idx_cortex]\n    cortex_prob = cortex_prob / cortex_prob.sum()\n    return cortex_prob\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.BlurCortex.__call__","title":"<code>__call__(output, seg, device, genparams={}, **kwargs)</code>","text":"<p>Apply the blurring to the input image.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Tensor</code> <p>Input image to resample.</p> required <code>seg</code> <code>Tensor</code> <p>Input segmentation corresponding to the image.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>genparams</code> <code>dict</code> <p>Generation parameters. Default: {}. Should contain the key \"spacing\" if the spacing is fixed.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Tensor, dict]</code> <p>Resampled image  and Metadata containing the blurring parameters.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def __call__(\n    self, output, seg, device, genparams: dict = {}, **kwargs\n) -&gt; tuple[torch.Tensor, dict]:\n    \"\"\"Apply the blurring to the input image.\n\n    Args:\n        output (torch.Tensor): Input image to resample.\n        seg (torch.Tensor): Input segmentation corresponding to the image.\n        device (str): Device to use for computation.\n        genparams (dict): Generation parameters.\n            Default: {}. Should contain the key \"spacing\" if the spacing is fixed.\n\n    Returns:\n        Resampled image  and Metadata containing the blurring parameters.\n    \"\"\"\n    if np.random.rand() &lt; self.prob or len(genparams.keys()) &gt; 0:\n        nblur = (\n            np.random.randint(self.nblur_min, self.nblur_max)\n            if \"nblur\" not in genparams.keys()\n            else genparams[\"nblur\"]\n        )\n        std_blurs = np.random.gamma(self.std_blur_shape, self.std_blur_scale, 3)\n\n        cortex = seg == self.cortex_label\n        cortex_prob = self.blur_proba(output.shape, cortex, device)\n        # Reshape cortex prob onto to the cortex\n\n        idx = torch.multinomial(cortex_prob, nblur)\n\n        idx_cortex = torch.where(cortex &gt; 0)\n        centers = [\n            [idx_cortex[i][id.item()].item() for i in range(3)] for id in idx\n        ]\n        # Spatial merging parameters.\n        sigmas = np.random.gamma(\n            self.sigma_gamma_loc, self.sigma_gamma_scale, (nblur, 3)\n        )\n        gaussian = mog_3d_tensor(\n            output.shape,\n            centers=centers,\n            sigmas=sigmas,\n            device=output.device,\n        )\n\n        # Generate the blurred image\n        output_blur = gaussian_blur_3d(\n            output.float(), stds=std_blurs, device=output.device\n        )\n        output = output * (1 - gaussian) + output_blur * gaussian\n        return output, {\n            \"nblur\": nblur,\n        }\n\n    else:\n        return output, {\n            \"nblur\": None,\n        }\n</code></pre>"},{"location":"sr_artif_api/#skull-stripping-artifacts","title":"Skull stripping artifacts","text":"<p>Default configuration: <pre><code>  _target_: fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries\n  prob_no_mask: 0.5\n  prob_if_mask_halo: 0.5\n  prob_if_mask_fuzzy: 0.5\n</code></pre> </p>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries","title":"<code>fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries</code>","text":"<p>               Bases: <code>RandTransform</code></p> <p>Simulates various types of boundaries in the image, either doing no masking (with probability <code>prob_no_mask</code>), adding a halo around the mask (with probability <code>prob_if_mask_halo</code>), or adding fuzzy boundaries to the mask (with probability <code>prob_if_mask_fuzzy</code>).</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>class SimulatedBoundaries(RandTransform):\n    \"\"\"\n    Simulates various types of boundaries in the image, either doing no masking\n    (with probability `prob_no_mask`), adding a halo around the mask (with probability\n    `prob_if_mask_halo`), or adding fuzzy boundaries to the mask (with probability `prob_if_mask_fuzzy`).\n    \"\"\"\n\n    def __init__(\n        self,\n        prob_no_mask: float,\n        prob_if_mask_halo: float,\n        prob_if_mask_fuzzy: float,\n    ):\n        \"\"\"\n        Initialize the augmentation parameters.\n\n        Args:\n            prob_no_mask (float): Probability of not applying any mask.\n            prob_if_mask_halo (float): Probability of applying a halo around the mask (in case masking is enabled).\n            prob_if_mask_fuzzy (float): Probability of applying fuzzy boundaries to the mask (in case masking is enabled).\n\n\n        \"\"\"\n        self.prob_no_mask = prob_no_mask\n        self.prob_halo = prob_if_mask_halo\n        self.prob_fuzzy = prob_if_mask_fuzzy\n        self.reset_seeds()\n\n    def reset_seeds(self):\n        \"\"\"\n        Reset the seeds for the augmentation.\n        \"\"\"\n        self.no_mask_on = None\n        self.halo_on = None\n        self.halo_radius = None\n        self.fuzzy_on = None\n        self.n_generate_fuzzy = None\n        self.n_centers = None\n        self.base_sigma = None\n\n    def sample_seeds(self):\n        \"\"\"\n        Sample the seeds for the augmentation.\n        \"\"\"\n        self.reset_seeds()\n        self.no_mask_on = np.random.rand() &lt; self.prob_no_mask\n        if not self.no_mask_on:\n            self.halo_on = np.random.rand() &lt; self.prob_halo\n            if self.halo_on:\n                self.halo_radius = np.random.randint(5, 15)\n            self.fuzzy_on = np.random.rand() &lt; self.prob_fuzzy\n            if self.fuzzy_on:\n                self.n_generate_fuzzy = np.random.randint(2, 5)\n                self.n_centers = np.random.poisson(100)\n                self.base_sigma = np.random.poisson(8)\n\n    def build_halo(self, mask, radius) -&gt; torch.Tensor:\n        \"\"\"\n        Build a halo around the mask with a given radius.\n\n        Args:\n            mask (torch.Tensor): Input mask.\n            radius (int): Radius of the halo.\n\n        Returns:\n            Mask with the halo.\n        \"\"\"\n        device = mask.device\n        kernel = torch.tensor(ball(radius)).float().to(device).unsqueeze(0).unsqueeze(0)\n        mask = mask.float().view(1, 1, *mask.shape[-3:])\n        mask = torch.nn.functional.conv3d(mask, kernel, padding=\"same\")\n        return (mask &gt; 0).int().view(*mask.shape[-3:])\n\n    def generate_fuzzy_boundaries(\n        self, mask, kernel_size=7, threshold_filter=3\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Generate fuzzy boundaries around the mask.\n\n        Args:\n            mask (torch.Tensor): Input mask.\n            kernel_size (int): Size of the kernel for the dilation.\n            threshold_filter (int): Threshold for the count of neighboring voxels.\n\n        Returns:\n            Mask with fuzzy boundaries.\n        \"\"\"\n        shape = mask.shape\n        diff = (dilate(mask, kernel_size) - mask).view(shape[-3:])\n        non_zero = diff.nonzero(as_tuple=True)\n        idx = torch.randperm(len(non_zero[0]))[: int(len(non_zero[0]) * 0.9)]\n        idx = (non_zero[0][idx], non_zero[1][idx], non_zero[2][idx])\n        diff[idx] = 0\n\n        dsamp = (apply_kernel(diff).squeeze() &gt; threshold_filter).bool()\n        closing = erode(dilate(torch.clamp(mask + dsamp, 0, 1), 5), 5)\n        return closing.view(shape)\n\n    def __call__(\n        self, output, seg, device, genparams: dict = {}, **kwargs\n    ) -&gt; tuple[torch.Tensor, dict]:\n        \"\"\"\n        Apply the simulated boundaries to the input image.\n\n        Args:\n            output (torch.Tensor): Input image to resample.\n            seg (torch.Tensor): Input segmentation corresponding to the image.\n            device (str): Device to use for computation.\n            genparams (dict): Generation parameters.\n\n        Returns:\n            Image with structured noise and metadata containing the structured noise parameters.\n\n        \"\"\"\n        device = seg.device\n        mask = (seg &gt; 0).int()\n        mask = mask.clone()\n\n        self.sample_seeds()\n        metadata = {\n            \"no_mask_on\": self.no_mask_on,\n            \"halo_on\": self.halo_on,\n            \"fuzzy_on\": self.fuzzy_on,\n        }\n\n        if self.no_mask_on:\n            return output, metadata\n        if self.halo_on:\n            mask = self.build_halo(mask, self.halo_radius)\n\n        if self.fuzzy_on:\n            # Generate fuzzy boundaries for the mask\n            mask_modif = mask.clone()\n            for _ in range(self.n_generate_fuzzy):\n                mask_modif = self.generate_fuzzy_boundaries(mask_modif)\n\n            # Sample centers in the voxels that have been added\n            # with a MoG\n\n            surf = torch.where((mask_modif - mask).squeeze() &gt; 0)\n            idx = torch.randperm(surf[0].shape[0])[: self.n_centers]\n            centers = [(surf[0][i], surf[1][i], surf[2][i]) for i in idx]\n            sigmas = [\n                self.base_sigma + 10 * np.random.beta(2, 5) for _ in range(len(centers))\n            ]\n            mog = mog_3d_tensor(\n                mask_modif.shape[-3:],\n                centers=centers,\n                sigmas=sigmas,\n                device=device,\n            ).view(1, 1, *mask_modif.shape[-3:])\n\n            # Generate the probability map for the surface\n\n            surf_proba = torch.zeros_like(mog[0, 0]).float()\n            surf_proba[surf] = mog[0, 0][surf]\n            # Generate kernel_size-1 x n_generate_fuzzy -1 dilations\n            # Roughly matches the width of the generated halo\n            n_dilate = 6 * (self.n_generate_fuzzy - 1)\n\n            # Then, generate more realistic boundaries by making the\n            # boundary of the bask more or less large according to the\n            # probability map.\n            dilate_stack = [mask] * 2\n            for i in range(n_dilate - 2):\n                dilate_stack.append(self.build_halo(dilate_stack[-1], 1))\n\n            # Generate a stack of dilations intersected with the mask\n            dilate_stack = torch.stack(dilate_stack, 0) * mask_modif.view(\n                1, *mask_modif.shape[-3:]\n            )\n\n            surf_proba = torch.clamp(\n                (surf_proba * len(dilate_stack) - 1).round().int(), 0, None\n            )\n\n            # Generate the final mask with the fuzzily generated boundaries\n            # and also randomized halos.\n            one_hot = torch.nn.functional.one_hot(\n                surf_proba.to(torch.int64), num_classes=len(dilate_stack)\n            ).int()\n            dilate_stack = dilate_stack.permute(1, 2, 3, 0).int()\n            mask = (one_hot * dilate_stack).sum(-1)\n        return output * mask, metadata\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries.__init__","title":"<code>__init__(prob_no_mask, prob_if_mask_halo, prob_if_mask_fuzzy)</code>","text":"<p>Initialize the augmentation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>prob_no_mask</code> <code>float</code> <p>Probability of not applying any mask.</p> required <code>prob_if_mask_halo</code> <code>float</code> <p>Probability of applying a halo around the mask (in case masking is enabled).</p> required <code>prob_if_mask_fuzzy</code> <code>float</code> <p>Probability of applying fuzzy boundaries to the mask (in case masking is enabled).</p> required Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def __init__(\n    self,\n    prob_no_mask: float,\n    prob_if_mask_halo: float,\n    prob_if_mask_fuzzy: float,\n):\n    \"\"\"\n    Initialize the augmentation parameters.\n\n    Args:\n        prob_no_mask (float): Probability of not applying any mask.\n        prob_if_mask_halo (float): Probability of applying a halo around the mask (in case masking is enabled).\n        prob_if_mask_fuzzy (float): Probability of applying fuzzy boundaries to the mask (in case masking is enabled).\n\n\n    \"\"\"\n    self.prob_no_mask = prob_no_mask\n    self.prob_halo = prob_if_mask_halo\n    self.prob_fuzzy = prob_if_mask_fuzzy\n    self.reset_seeds()\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries.reset_seeds","title":"<code>reset_seeds()</code>","text":"<p>Reset the seeds for the augmentation.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def reset_seeds(self):\n    \"\"\"\n    Reset the seeds for the augmentation.\n    \"\"\"\n    self.no_mask_on = None\n    self.halo_on = None\n    self.halo_radius = None\n    self.fuzzy_on = None\n    self.n_generate_fuzzy = None\n    self.n_centers = None\n    self.base_sigma = None\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries.sample_seeds","title":"<code>sample_seeds()</code>","text":"<p>Sample the seeds for the augmentation.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def sample_seeds(self):\n    \"\"\"\n    Sample the seeds for the augmentation.\n    \"\"\"\n    self.reset_seeds()\n    self.no_mask_on = np.random.rand() &lt; self.prob_no_mask\n    if not self.no_mask_on:\n        self.halo_on = np.random.rand() &lt; self.prob_halo\n        if self.halo_on:\n            self.halo_radius = np.random.randint(5, 15)\n        self.fuzzy_on = np.random.rand() &lt; self.prob_fuzzy\n        if self.fuzzy_on:\n            self.n_generate_fuzzy = np.random.randint(2, 5)\n            self.n_centers = np.random.poisson(100)\n            self.base_sigma = np.random.poisson(8)\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries.build_halo","title":"<code>build_halo(mask, radius)</code>","text":"<p>Build a halo around the mask with a given radius.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Tensor</code> <p>Input mask.</p> required <code>radius</code> <code>int</code> <p>Radius of the halo.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Mask with the halo.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def build_halo(self, mask, radius) -&gt; torch.Tensor:\n    \"\"\"\n    Build a halo around the mask with a given radius.\n\n    Args:\n        mask (torch.Tensor): Input mask.\n        radius (int): Radius of the halo.\n\n    Returns:\n        Mask with the halo.\n    \"\"\"\n    device = mask.device\n    kernel = torch.tensor(ball(radius)).float().to(device).unsqueeze(0).unsqueeze(0)\n    mask = mask.float().view(1, 1, *mask.shape[-3:])\n    mask = torch.nn.functional.conv3d(mask, kernel, padding=\"same\")\n    return (mask &gt; 0).int().view(*mask.shape[-3:])\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries.generate_fuzzy_boundaries","title":"<code>generate_fuzzy_boundaries(mask, kernel_size=7, threshold_filter=3)</code>","text":"<p>Generate fuzzy boundaries around the mask.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Tensor</code> <p>Input mask.</p> required <code>kernel_size</code> <code>int</code> <p>Size of the kernel for the dilation.</p> <code>7</code> <code>threshold_filter</code> <code>int</code> <p>Threshold for the count of neighboring voxels.</p> <code>3</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Mask with fuzzy boundaries.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def generate_fuzzy_boundaries(\n    self, mask, kernel_size=7, threshold_filter=3\n) -&gt; torch.Tensor:\n    \"\"\"\n    Generate fuzzy boundaries around the mask.\n\n    Args:\n        mask (torch.Tensor): Input mask.\n        kernel_size (int): Size of the kernel for the dilation.\n        threshold_filter (int): Threshold for the count of neighboring voxels.\n\n    Returns:\n        Mask with fuzzy boundaries.\n    \"\"\"\n    shape = mask.shape\n    diff = (dilate(mask, kernel_size) - mask).view(shape[-3:])\n    non_zero = diff.nonzero(as_tuple=True)\n    idx = torch.randperm(len(non_zero[0]))[: int(len(non_zero[0]) * 0.9)]\n    idx = (non_zero[0][idx], non_zero[1][idx], non_zero[2][idx])\n    diff[idx] = 0\n\n    dsamp = (apply_kernel(diff).squeeze() &gt; threshold_filter).bool()\n    closing = erode(dilate(torch.clamp(mask + dsamp, 0, 1), 5), 5)\n    return closing.view(shape)\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulatedBoundaries.__call__","title":"<code>__call__(output, seg, device, genparams={}, **kwargs)</code>","text":"<p>Apply the simulated boundaries to the input image.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Tensor</code> <p>Input image to resample.</p> required <code>seg</code> <code>Tensor</code> <p>Input segmentation corresponding to the image.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>genparams</code> <code>dict</code> <p>Generation parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Tensor, dict]</code> <p>Image with structured noise and metadata containing the structured noise parameters.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def __call__(\n    self, output, seg, device, genparams: dict = {}, **kwargs\n) -&gt; tuple[torch.Tensor, dict]:\n    \"\"\"\n    Apply the simulated boundaries to the input image.\n\n    Args:\n        output (torch.Tensor): Input image to resample.\n        seg (torch.Tensor): Input segmentation corresponding to the image.\n        device (str): Device to use for computation.\n        genparams (dict): Generation parameters.\n\n    Returns:\n        Image with structured noise and metadata containing the structured noise parameters.\n\n    \"\"\"\n    device = seg.device\n    mask = (seg &gt; 0).int()\n    mask = mask.clone()\n\n    self.sample_seeds()\n    metadata = {\n        \"no_mask_on\": self.no_mask_on,\n        \"halo_on\": self.halo_on,\n        \"fuzzy_on\": self.fuzzy_on,\n    }\n\n    if self.no_mask_on:\n        return output, metadata\n    if self.halo_on:\n        mask = self.build_halo(mask, self.halo_radius)\n\n    if self.fuzzy_on:\n        # Generate fuzzy boundaries for the mask\n        mask_modif = mask.clone()\n        for _ in range(self.n_generate_fuzzy):\n            mask_modif = self.generate_fuzzy_boundaries(mask_modif)\n\n        # Sample centers in the voxels that have been added\n        # with a MoG\n\n        surf = torch.where((mask_modif - mask).squeeze() &gt; 0)\n        idx = torch.randperm(surf[0].shape[0])[: self.n_centers]\n        centers = [(surf[0][i], surf[1][i], surf[2][i]) for i in idx]\n        sigmas = [\n            self.base_sigma + 10 * np.random.beta(2, 5) for _ in range(len(centers))\n        ]\n        mog = mog_3d_tensor(\n            mask_modif.shape[-3:],\n            centers=centers,\n            sigmas=sigmas,\n            device=device,\n        ).view(1, 1, *mask_modif.shape[-3:])\n\n        # Generate the probability map for the surface\n\n        surf_proba = torch.zeros_like(mog[0, 0]).float()\n        surf_proba[surf] = mog[0, 0][surf]\n        # Generate kernel_size-1 x n_generate_fuzzy -1 dilations\n        # Roughly matches the width of the generated halo\n        n_dilate = 6 * (self.n_generate_fuzzy - 1)\n\n        # Then, generate more realistic boundaries by making the\n        # boundary of the bask more or less large according to the\n        # probability map.\n        dilate_stack = [mask] * 2\n        for i in range(n_dilate - 2):\n            dilate_stack.append(self.build_halo(dilate_stack[-1], 1))\n\n        # Generate a stack of dilations intersected with the mask\n        dilate_stack = torch.stack(dilate_stack, 0) * mask_modif.view(\n            1, *mask_modif.shape[-3:]\n        )\n\n        surf_proba = torch.clamp(\n            (surf_proba * len(dilate_stack) - 1).round().int(), 0, None\n        )\n\n        # Generate the final mask with the fuzzily generated boundaries\n        # and also randomized halos.\n        one_hot = torch.nn.functional.one_hot(\n            surf_proba.to(torch.int64), num_classes=len(dilate_stack)\n        ).int()\n        dilate_stack = dilate_stack.permute(1, 2, 3, 0).int()\n        mask = (one_hot * dilate_stack).sum(-1)\n    return output * mask, metadata\n</code></pre>"},{"location":"sr_artif_api/#structural-noise","title":"Structural noise","text":"<p>Default configuration: <pre><code>struct_noise:\n  _target_: fetalsyngen.generator.augmentation.artifacts.StructNoise\n  prob: 0.4\n  wm_label: 3\n  std_min: 0.2\n  std_max: 0.4\n  nloc_min: 5\n  nloc_max: 15\n</code></pre> </p>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.StructNoise","title":"<code>fetalsyngen.generator.augmentation.artifacts.StructNoise</code>","text":"<p>               Bases: <code>RandTransform</code></p> <p>Adds a structured noise to the white matter in the image, similar to what can be seen with NeSVoR reconstructions without prior denoising.</p> <p>Given a <code>wm_label</code>, generates a multi-scale noise (between <code>nstages_min</code> and <code>nstages_max</code> stages) with a standard deviation between <code>std_min</code> and <code>std_max</code>.</p> <p>The noise is then added in a spatially varying manner at <code>nloc</code> locations ( between <code>n_loc_min</code> and <code>n_loc_max</code> locations) in the white matter. The merging is done as a weighted sum of the original image and the noisy image, with the weights defined by a MoG with centers at the <code>nloc</code> locations and sigmas defined by <code>sigma_mu</code> and <code>sigma_std</code>.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>class StructNoise(RandTransform):\n    \"\"\"Adds a structured noise to the white matter in the image, similar to\n    what can be seen with NeSVoR reconstructions without prior denoising.\n\n    Given a `wm_label`, generates a multi-scale noise (between `nstages_min` and `nstages_max` stages)\n    with a standard deviation between `std_min` and `std_max`.\n\n    The noise is then added in a spatially varying manner at `nloc` locations (\n    between `n_loc_min` and `n_loc_max` locations) in the white matter. The merging\n    is done as a weighted sum of the original image and the noisy image, with the weights\n    defined by a MoG with centers at the `nloc` locations and sigmas defined by `sigma_mu` and\n    `sigma_std`.\n    \"\"\"\n\n    ### TO REFACTOR: THIS IS PERLIN NOISE\n    def __init__(\n        self,\n        prob: float,\n        wm_label: int,\n        std_min: float,\n        std_max: float,\n        nloc_min: int,\n        nloc_max: int,\n        nstages_min: int = 1,\n        nstages_max: int = 5,\n        sigma_mu: int = 25,\n        sigma_std: int = 5,\n    ):\n        \"\"\"\n        Initialize the augmentation parameters.\n\n        Args:\n            prob (float): Probability of applying the augmentation.\n            wm_label (int): Label of the white matter in the segmentation.\n            std_min (float): Minimum standard deviation of the noise.\n            std_max (float): Maximum standard deviation of the noise.\n            nloc_min (int): Minimum number of locations to add noise.\n            nloc_max (int): Maximum number of locations to add noise.\n            nstages_min (int): Minimum number of stages for the noise.\n            nstages_max (int): Maximum number of stages for the noise.\n            sigma_mu (int): Mean of the sigmas for the MoG.\n            sigma_std (int): Standard deviation of the sigmas for the MoG.\n\n        \"\"\"\n        self.prob = prob\n        self.wm_label = wm_label\n        self.nstages_min = nstages_min\n        self.nstages_max = nstages_max\n        self.std_min = std_min\n        self.std_max = std_max\n        self.nloc_min = nloc_min\n        self.nloc_max = nloc_max\n        self.sigma_mu = sigma_mu\n        self.sigma_std = sigma_std\n\n    def __call__(\n        self, output, seg, device, genparams: dict = {}, **kwargs\n    ) -&gt; tuple[torch.Tensor, dict]:\n        \"\"\"\n        Apply the structured noise to the input image.\n\n        Args:\n            output (torch.Tensor): Input image to resample.\n            seg (torch.Tensor): Input segmentation corresponding to the image.\n            device (str): Device to use for computation.\n            genparams (dict): Generation parameters.\n\n        Returns:\n            Image with structured noise and metadata containing the structured noise parameters.\n        \"\"\"\n        if np.random.rand() &lt; self.prob or \"nloc\" in genparams.keys():\n            ## Parameters\n            nstages = (\n                np.random.randint(self.nstages_min, self.nstages_max)\n                if \"nstages\" not in genparams\n                else genparams[\"nstages\"]\n            )\n            noise_std = self.std_min + (self.std_max - self.std_min) * np.random.rand()\n            nloc = (\n                np.random.randint(\n                    self.nloc_min,\n                    self.nloc_max,\n                )\n                if \"nloc\" not in genparams\n                else genparams[\"nloc\"]\n            )\n            ##\n\n            wm = seg == self.wm_label\n            idx_wm = torch.nonzero(wm, as_tuple=True)\n            idx = torch.randint(0, len(idx_wm[0]), (nloc,))\n            mask = (seg &gt; 0).int()\n            # Add multiscale noise. Start with a small tensor and add the noise to it.\n            lr_gaussian_noise = torch.zeros(\n                [i // 2**nstages for i in output.shape]\n            ).to(device)\n\n            for k in range(nstages):\n                shape = [i // 2 ** (nstages - k) for i in output.shape]\n                next_shape = [i // 2 ** (nstages - 1 - k) for i in output.shape]\n                lr_gaussian_noise += torch.randn(shape).to(device)\n                lr_gaussian_noise = torch.nn.functional.interpolate(\n                    lr_gaussian_noise.unsqueeze(0).unsqueeze(0),\n                    size=next_shape,\n                    mode=\"trilinear\",\n                    align_corners=False,\n                ).squeeze()\n\n            lr_gaussian_noise = lr_gaussian_noise / torch.max(abs(lr_gaussian_noise))\n            output_noisy = torch.clamp(\n                output + noise_std * lr_gaussian_noise, 0, output.max() * 2\n            )\n\n            sigmas = (\n                (\n                    torch.clamp(\n                        self.sigma_mu + self.sigma_std * torch.randn(len(idx)),\n                        1,\n                        40,\n                    )\n                )\n                .cpu()\n                .numpy()\n            )\n            centers = [\n                (\n                    idx_wm[0][id].item(),\n                    idx_wm[1][id].item(),\n                    idx_wm[2][id].item(),\n                )\n                for id in idx\n            ]\n            gaussian = mog_3d_tensor(\n                output.shape, centers=centers, sigmas=sigmas, device=device\n            )\n\n            output = output * (1 - mask) + mask * (\n                gaussian * output_noisy + (1 - gaussian) * output\n            )\n\n            args = {\n                \"nstages\": nstages,\n                \"noise_std\": noise_std,\n                \"nloc\": nloc,\n            }\n\n            return output, args\n        else:\n            return output, {}\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.StructNoise.__init__","title":"<code>__init__(prob, wm_label, std_min, std_max, nloc_min, nloc_max, nstages_min=1, nstages_max=5, sigma_mu=25, sigma_std=5)</code>","text":"<p>Initialize the augmentation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>prob</code> <code>float</code> <p>Probability of applying the augmentation.</p> required <code>wm_label</code> <code>int</code> <p>Label of the white matter in the segmentation.</p> required <code>std_min</code> <code>float</code> <p>Minimum standard deviation of the noise.</p> required <code>std_max</code> <code>float</code> <p>Maximum standard deviation of the noise.</p> required <code>nloc_min</code> <code>int</code> <p>Minimum number of locations to add noise.</p> required <code>nloc_max</code> <code>int</code> <p>Maximum number of locations to add noise.</p> required <code>nstages_min</code> <code>int</code> <p>Minimum number of stages for the noise.</p> <code>1</code> <code>nstages_max</code> <code>int</code> <p>Maximum number of stages for the noise.</p> <code>5</code> <code>sigma_mu</code> <code>int</code> <p>Mean of the sigmas for the MoG.</p> <code>25</code> <code>sigma_std</code> <code>int</code> <p>Standard deviation of the sigmas for the MoG.</p> <code>5</code> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def __init__(\n    self,\n    prob: float,\n    wm_label: int,\n    std_min: float,\n    std_max: float,\n    nloc_min: int,\n    nloc_max: int,\n    nstages_min: int = 1,\n    nstages_max: int = 5,\n    sigma_mu: int = 25,\n    sigma_std: int = 5,\n):\n    \"\"\"\n    Initialize the augmentation parameters.\n\n    Args:\n        prob (float): Probability of applying the augmentation.\n        wm_label (int): Label of the white matter in the segmentation.\n        std_min (float): Minimum standard deviation of the noise.\n        std_max (float): Maximum standard deviation of the noise.\n        nloc_min (int): Minimum number of locations to add noise.\n        nloc_max (int): Maximum number of locations to add noise.\n        nstages_min (int): Minimum number of stages for the noise.\n        nstages_max (int): Maximum number of stages for the noise.\n        sigma_mu (int): Mean of the sigmas for the MoG.\n        sigma_std (int): Standard deviation of the sigmas for the MoG.\n\n    \"\"\"\n    self.prob = prob\n    self.wm_label = wm_label\n    self.nstages_min = nstages_min\n    self.nstages_max = nstages_max\n    self.std_min = std_min\n    self.std_max = std_max\n    self.nloc_min = nloc_min\n    self.nloc_max = nloc_max\n    self.sigma_mu = sigma_mu\n    self.sigma_std = sigma_std\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.StructNoise.__call__","title":"<code>__call__(output, seg, device, genparams={}, **kwargs)</code>","text":"<p>Apply the structured noise to the input image.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Tensor</code> <p>Input image to resample.</p> required <code>seg</code> <code>Tensor</code> <p>Input segmentation corresponding to the image.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>genparams</code> <code>dict</code> <p>Generation parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Tensor, dict]</code> <p>Image with structured noise and metadata containing the structured noise parameters.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def __call__(\n    self, output, seg, device, genparams: dict = {}, **kwargs\n) -&gt; tuple[torch.Tensor, dict]:\n    \"\"\"\n    Apply the structured noise to the input image.\n\n    Args:\n        output (torch.Tensor): Input image to resample.\n        seg (torch.Tensor): Input segmentation corresponding to the image.\n        device (str): Device to use for computation.\n        genparams (dict): Generation parameters.\n\n    Returns:\n        Image with structured noise and metadata containing the structured noise parameters.\n    \"\"\"\n    if np.random.rand() &lt; self.prob or \"nloc\" in genparams.keys():\n        ## Parameters\n        nstages = (\n            np.random.randint(self.nstages_min, self.nstages_max)\n            if \"nstages\" not in genparams\n            else genparams[\"nstages\"]\n        )\n        noise_std = self.std_min + (self.std_max - self.std_min) * np.random.rand()\n        nloc = (\n            np.random.randint(\n                self.nloc_min,\n                self.nloc_max,\n            )\n            if \"nloc\" not in genparams\n            else genparams[\"nloc\"]\n        )\n        ##\n\n        wm = seg == self.wm_label\n        idx_wm = torch.nonzero(wm, as_tuple=True)\n        idx = torch.randint(0, len(idx_wm[0]), (nloc,))\n        mask = (seg &gt; 0).int()\n        # Add multiscale noise. Start with a small tensor and add the noise to it.\n        lr_gaussian_noise = torch.zeros(\n            [i // 2**nstages for i in output.shape]\n        ).to(device)\n\n        for k in range(nstages):\n            shape = [i // 2 ** (nstages - k) for i in output.shape]\n            next_shape = [i // 2 ** (nstages - 1 - k) for i in output.shape]\n            lr_gaussian_noise += torch.randn(shape).to(device)\n            lr_gaussian_noise = torch.nn.functional.interpolate(\n                lr_gaussian_noise.unsqueeze(0).unsqueeze(0),\n                size=next_shape,\n                mode=\"trilinear\",\n                align_corners=False,\n            ).squeeze()\n\n        lr_gaussian_noise = lr_gaussian_noise / torch.max(abs(lr_gaussian_noise))\n        output_noisy = torch.clamp(\n            output + noise_std * lr_gaussian_noise, 0, output.max() * 2\n        )\n\n        sigmas = (\n            (\n                torch.clamp(\n                    self.sigma_mu + self.sigma_std * torch.randn(len(idx)),\n                    1,\n                    40,\n                )\n            )\n            .cpu()\n            .numpy()\n        )\n        centers = [\n            (\n                idx_wm[0][id].item(),\n                idx_wm[1][id].item(),\n                idx_wm[2][id].item(),\n            )\n            for id in idx\n        ]\n        gaussian = mog_3d_tensor(\n            output.shape, centers=centers, sigmas=sigmas, device=device\n        )\n\n        output = output * (1 - mask) + mask * (\n            gaussian * output_noisy + (1 - gaussian) * output\n        )\n\n        args = {\n            \"nstages\": nstages,\n            \"noise_std\": noise_std,\n            \"nloc\": nloc,\n        }\n\n        return output, args\n    else:\n        return output, {}\n</code></pre>"},{"location":"sr_artif_api/#artifacts-related-to-the-wrong-fetal-motion-estimation-during-sr-reconstruction","title":"Artifacts related to the wrong fetal motion estimation during SR reconstruction","text":"<p>Default configuration: <pre><code>simulate_motion:\n  _target_: fetalsyngen.generator.augmentation.artifacts.SimulateMotion\n  prob: 0.4\n  scanner_params:\n    _target_: fetalsyngen.generator.artifacts.utils.ScannerParams\n    resolution_slice_fac_min: 0.5\n    resolution_slice_fac_max: 2\n    resolution_slice_max: 1.5\n    slice_thickness_min: 1.5\n    slice_thickness_max: 3.5\n    gap_min: 1.5\n    gap_max: 5.5\n    min_num_stack: 2\n    max_num_stack: 6\n    max_num_slices: 250\n    noise_sigma_min: 0\n    noise_sigma_max: 0.1\n    TR_min: 1\n    TR_max: 2\n    prob_gamma: 0.1\n    gamma_std: 0.05\n    prob_void: 0.2\n    slice_size: null\n    restrict_transform: False\n    txy: 3.0\n\n  recon_params:\n    _target_: fetalsyngen.generator.artifacts.utils.ReconParams\n    prob_misreg_slice: 0.08\n    slices_misreg_ratio: 0.1\n    prob_misreg_stack: 0.08\n    txy: 3.0\n    prob_merge: 0.8\n    merge_ngaussians_min: 2\n    merge_ngaussians_max: 4\n    prob_smooth: 0.2\n    prob_rm_slices: 0.3\n    rm_slices_min: 0.1\n    rm_slices_max: 0.4\n</code></pre></p>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulateMotion","title":"<code>fetalsyngen.generator.augmentation.artifacts.SimulateMotion</code>","text":"<p>               Bases: <code>RandTransform</code></p> <p>Simulates motion in the image by simulating low-resolution slices (based on the <code>scanner_params</code> and then doing a simple point-spread function based on the low-resolution slices (using <code>recon_params</code>).</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>class SimulateMotion(RandTransform):\n    \"\"\"\n    Simulates motion in the image by simulating low-resolution slices (based\n    on the `scanner_params` and then doing a simple point-spread function based\n    on the low-resolution slices (using `recon_params`).\n    \"\"\"\n\n    def __init__(\n        self,\n        prob: float,\n        scanner_params: ScannerParams,\n        recon_params: ReconParams,\n    ):\n        \"\"\"\n        Initialize the augmentation parameters.\n\n        Args:\n            prob (float): Probability of applying the augmentation.\n            scanner_params (ScannerParams): Dataclass of parameters for the scanner.\n            recon_params (ReconParams): Dataclass of parameters for the reconstructor.\n\n        \"\"\"\n        self.scanner_args = scanner_params\n        self.recon_args = recon_params\n        self.prob = prob\n\n    def __call__(\n        self, output, seg, device, genparams: dict = {}, **kwargs\n    ) -&gt; tuple[torch.Tensor, dict]:\n        \"\"\"\n        Apply the motion simulation to the input image.\n\n        Args:\n            output (torch.Tensor): Input image to resample.\n            seg (torch.Tensor): Input segmentation corresponding to the image.\n            device (str): Device to use for computation.\n            genparams (dict): Generation parameters.\n\n        Returns:\n            Image with simulated motion and metadata containing the motion simulation parameters.\n        \"\"\"\n        # def _artifact_simulate_motion(self, im, seg, generator_params, res):\n\n        if np.random.rand() &lt; self.prob:\n            device = output.device\n            dshape = (1, 1, *output.shape[-3:])\n            res = kwargs[\"resolution\"]\n            res_ = np.float64(res[0])\n            metadata = {}\n            d = {\n                \"resolution\": res_,\n                \"volume\": output.view(dshape).float().to(device),\n                \"mask\": (seg &gt; 0).view(dshape).float().to(device),\n                \"seg\": seg.view(dshape).float().to(device),\n                \"affine\": torch.diag(torch.tensor(list(res) + [1])).to(device),\n                \"threshold\": 0.1,\n            }\n            self.scanner_args.resolution_recon = res_\n            scanner = Scanner(**asdict(self.scanner_args))\n            d_scan = scanner.scan(d)\n\n            recon = PSFReconstructor(**asdict(self.recon_args))\n            output, _ = recon.recon_psf(d_scan)\n\n            metadata.update(\n                {\n                    \"resolution_recon\": d_scan[\"resolution_recon\"],\n                    \"resolution_slice\": d_scan[\"resolution_slice\"],\n                    \"slice_thickness\": d_scan[\"slice_thickness\"],\n                    \"gap\": d_scan[\"gap\"],\n                    \"nstacks\": len(torch.unique(d_scan[\"positions\"][:, 1])),\n                }\n            )\n            metadata.update(recon.get_seeds())\n\n            return output.squeeze(), metadata\n        else:\n            return output, {}\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulateMotion.__init__","title":"<code>__init__(prob, scanner_params, recon_params)</code>","text":"<p>Initialize the augmentation parameters.</p> <p>Parameters:</p> Name Type Description Default <code>prob</code> <code>float</code> <p>Probability of applying the augmentation.</p> required <code>scanner_params</code> <code>ScannerParams</code> <p>Dataclass of parameters for the scanner.</p> required <code>recon_params</code> <code>ReconParams</code> <p>Dataclass of parameters for the reconstructor.</p> required Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def __init__(\n    self,\n    prob: float,\n    scanner_params: ScannerParams,\n    recon_params: ReconParams,\n):\n    \"\"\"\n    Initialize the augmentation parameters.\n\n    Args:\n        prob (float): Probability of applying the augmentation.\n        scanner_params (ScannerParams): Dataclass of parameters for the scanner.\n        recon_params (ReconParams): Dataclass of parameters for the reconstructor.\n\n    \"\"\"\n    self.scanner_args = scanner_params\n    self.recon_args = recon_params\n    self.prob = prob\n</code></pre>"},{"location":"sr_artif_api/#fetalsyngen.generator.augmentation.artifacts.SimulateMotion.__call__","title":"<code>__call__(output, seg, device, genparams={}, **kwargs)</code>","text":"<p>Apply the motion simulation to the input image.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>Tensor</code> <p>Input image to resample.</p> required <code>seg</code> <code>Tensor</code> <p>Input segmentation corresponding to the image.</p> required <code>device</code> <code>str</code> <p>Device to use for computation.</p> required <code>genparams</code> <code>dict</code> <p>Generation parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[Tensor, dict]</code> <p>Image with simulated motion and metadata containing the motion simulation parameters.</p> Source code in <code>fetalsyngen/generator/augmentation/artifacts.py</code> <pre><code>def __call__(\n    self, output, seg, device, genparams: dict = {}, **kwargs\n) -&gt; tuple[torch.Tensor, dict]:\n    \"\"\"\n    Apply the motion simulation to the input image.\n\n    Args:\n        output (torch.Tensor): Input image to resample.\n        seg (torch.Tensor): Input segmentation corresponding to the image.\n        device (str): Device to use for computation.\n        genparams (dict): Generation parameters.\n\n    Returns:\n        Image with simulated motion and metadata containing the motion simulation parameters.\n    \"\"\"\n    # def _artifact_simulate_motion(self, im, seg, generator_params, res):\n\n    if np.random.rand() &lt; self.prob:\n        device = output.device\n        dshape = (1, 1, *output.shape[-3:])\n        res = kwargs[\"resolution\"]\n        res_ = np.float64(res[0])\n        metadata = {}\n        d = {\n            \"resolution\": res_,\n            \"volume\": output.view(dshape).float().to(device),\n            \"mask\": (seg &gt; 0).view(dshape).float().to(device),\n            \"seg\": seg.view(dshape).float().to(device),\n            \"affine\": torch.diag(torch.tensor(list(res) + [1])).to(device),\n            \"threshold\": 0.1,\n        }\n        self.scanner_args.resolution_recon = res_\n        scanner = Scanner(**asdict(self.scanner_args))\n        d_scan = scanner.scan(d)\n\n        recon = PSFReconstructor(**asdict(self.recon_args))\n        output, _ = recon.recon_psf(d_scan)\n\n        metadata.update(\n            {\n                \"resolution_recon\": d_scan[\"resolution_recon\"],\n                \"resolution_slice\": d_scan[\"resolution_slice\"],\n                \"slice_thickness\": d_scan[\"slice_thickness\"],\n                \"gap\": d_scan[\"gap\"],\n                \"nstacks\": len(torch.unique(d_scan[\"positions\"][:, 1])),\n            }\n        )\n        metadata.update(recon.get_seeds())\n\n        return output.squeeze(), metadata\n    else:\n        return output, {}\n</code></pre>"},{"location":"sr_artif_api/#references","title":"References","text":"<ol> <li>Sanchez, Thomas, et al. \"Assessing data quality on fetal brain MRI reconstruction: a multi-site and multi-rater study.\" International Workshop on Preterm, Perinatal and Paediatric Image Analysis. Cham: Springer Nature Switzerland, 2024.</li> </ol>"},{"location":"usage/","title":"How to use the generator?","text":"<p>Follow these steps to integrate and use the generator in your project:</p>"},{"location":"usage/#1-install-the-package","title":"1. Install the Package","text":"<p>Refer to the Installation page for detailed instructions on how to install the package.</p>"},{"location":"usage/#2-prepare-the-dataset","title":"2. Prepare the Dataset","text":"<p>Ensure your dataset is formatted according to the BIDS format. Your dataset must include the following files:</p> <ul> <li>T2w image: Files should have the naming pattern <code>*_T2w.nii.gz</code>.</li> <li>Segmentation mask: Files should have the naming pattern <code>*_dseg.nii.gz</code>.</li> <li>Seeds: Seeds used for subclass generation. It is recommended to store them in a separate folder within the BIDS dataset, such as <code>derivatives/seeds</code>.</li> </ul> <p>Note</p> <p>\ud83d\udcdd Seeds: The seeds must be generated using the <code>generate_seeds.py</code> script provided in the package. See the seed generation page for more details.</p> <p>\ud83d\udcdd Resampling: For the correct work of the generator, all input data needs to be resampled to the same spatial size and resolution. Please perform this step before seed generation.</p>"},{"location":"usage/#3-copy-dataset-configurations","title":"3. Copy Dataset Configurations","text":"<p>We provide a variety of ready-to-use configurations for different tasks. These configuration files are stored in the <code>fetalsyngen/configs/dataset</code> folder and are further detailed in the Configs page.</p> <p>Each configuration is a <code>.yaml</code> file that contains the parameters for the generation pipeline. You can modify these configurations to suit the specific requirements of your project.</p>"},{"location":"usage/#4-run-the-generator","title":"4. Run the Generator","text":"<p>We offer several <code>torch.Dataset</code> classes for loading synthetic and real datasets:</p> <ul> <li><code>fetalsyngen.data.datasets.FetalTestDataset</code>: Loads real images and segmentations. Used for testing and validation on real data.</li> <li><code>fetalsyngen.data.datasets.FetalSynthDataset</code>: Can be used to either to create synthetic images and segmentation on the fly or apply the same transformations used in generation of synthetic data to real images and segmentations.</li> </ul> <p>For more details on these datasets, see the Datasets page.</p> <p>Note</p> <p>\ud83d\udcdd Configs: Use the local copy of the config files from your repository to instantiate the generator/dataset classes.</p> <p>\ud83d\udcdd Paths: When using the dataset classes, ensure that the paths in your local configuration files are updated to correctly reference your dataset and seed files.</p>"}]}